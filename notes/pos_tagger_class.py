# -*- coding: utf-8 -*-
"""Pos tagger class.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RK4QI4DYqtg4nmav42H5pakm27T0C1a5
"""

import nltk

from nltk import pos_tag

from nltk.tokenize import word_tokenize

text = "They received the best film of the year award."    #POS tag the given sentence

text_tokens = word_tokenize(text)      #tokenize the words

nltk.download('punkt')          #required for word_tokenize. Punkt Sentence Tokenizer. This tokenizer divides a text into a list of sentences by using an unsupervised algorithm to build a model for abbreviation words, collocations, and words that start sentences.

print (text_tokens)

text_tagged = pos_tag(text_tokens)     #Pos tag the above sentence

nltk.download('averaged_perceptron_tagger')    #the default tagger of NLTK

print (text_tagged)          #print the tags for the words

from nltk import pos_tag_sents       #pos_tag_sents() for efficient tagging of more than one sentence.

from nltk.tokenize import word_tokenize, sent_tokenize

text = "The goal was to best the competition. His latest song was a personal best. Hence, he received the best song of the year award. He played best after a couple of martinis."

text_sentence_tokens = word_tokenize(text)

print (text_sentence_tokens)

text_word_tokens = []
for sentence_token in text_sentence_tokens:
    text_word_tokens.append(word_tokenize(sentence_token))

print (text_word_tokens)

text_tagged = pos_tag_sents(text_word_tokens)

print (text_tagged)

text = word_tokenize("They refuse to permit us to obtain the refuse permit")     #here first refuse is a verb and second is a noun

nltk.pos_tag(text)

text = nltk.Text(word.lower() for word in nltk.corpus.brown.words())

text.similar('woman')   #similar(token) returns a list of words that appear in the same context as token

text.similar('bought')

from nltk.corpus import brown      #import brown corpus

print(brown.words())          #prints words from brown corpus

print(brown.tagged_words())

print(brown.sents())

print(brown.tagged_sents())

print(brown.paras(categories='reviews'))        #print paras of brown category reviews

print(brown.tagged_paras(categories='reviews'))

from nltk.tag.util import str2tuple    #str2tuple() Given the string representation of a tagged token, return the corresponding tuple representation.

str2tuple('fly/NN')

tagged_token = nltk.tag.str2tuple('Learn/VB')  #assign to a variable

tagged_token

tagged_token[0]

tagged_token[1]

sent = '''
... The/AT grand/JJ jury/NN commented/VBD on/IN a/AT number/NN of/IN
... other/AP topics/NNS ,/, AMONG/IN them/PPO the/AT Atlanta/NP and/CC
... Fulton/NP-tl County/NN-tl purchasing/VBG departments/NNS which/WDT it/PPS
... said/VBD ``/`` ARE/BER well/QL operated/VBN and/CC follow/VB generally/RB
... accepted/VBN practices/NNS which/WDT inure/VB to/IN the/AT best/JJT
... interest/NN of/IN both/ABX governments/NNS ''/'' ./.
... '''

[nltk.tag.str2tuple(t) for t in sent.split()]

import nltk
nltk.download('universal_tagset')
nltk.corpus.brown.tagged_words(tagset='universal')    #brown copus with tagset "Universal tagset". Penn Treebank tagset is default

from nltk.corpus import brown     #print words with 'to' inbetween
def process(sentence):
    for (w1,t1), (w2,t2), (w3,t3) in nltk.trigrams(sentence):
        if (t1.startswith('V') and t2 == 'TO' and t3.startswith('V')):
            print(w1, w2, w3)

for tagged_sent in brown.tagged_sents():
...     process(tagged_sent)

pos = {}   #pos is an empty dictionary

pos

pos['colorless'] = 'ADJ'   #Assign key value pairs

pos['ideas'] = 'N'

pos['sleep'] = 'V'

pos['furiously'] = 'ADV'

pos

pos['ideas']

pos['colorless']

list(pos) #just find the keys, we can convert the dictionary to a list

sorted(pos)

[w for w in pos if w.endswith('s')]

for word in sorted(pos):
...     print(word + ":", pos[word])

list(pos.keys())#dictionary methods keys(), values() and items() allow us to access the keys, values, and key-value pairs as separate lists.

list(pos.values())

list(pos.items())

for key, val in sorted(pos.items()):
    print(key + ":", val)

pos['sleep'] = ['N','V'] #storing multiple values in that entry

print(pos)

pos

pos = {'colorless': 'ADJ', 'ideas': 'N', 'sleep': 'V', 'furiously': 'ADV'} #defining dictionary

pos

pos = dict(colorless='ADJ', ideas='N', sleep='V', furiously='ADV')

pos

Dict = {1: 'Geeks', 2: 'For', 3: 'Geeks'}
print("Dictionary:")
print(Dict)
print(Dict[1])

Dict = {1: 'Geeks', 2: 'For', 3: 'Geeks'}
print("Dictionary:")
print(Dict)
print(Dict[1])

print(Dict[4])    #observe this raises error

# The functionality of both dictionaries and defaultdict are almost same except for the fact that defaultdict never raises a KeyError. It provides a default value for the key that does not exists.

from collections import defaultdict
frequency = defaultdict(int)
frequency['colorless'] = 4
frequency['ideas']

pos = defaultdict(list)
>>> pos['sleep'] = ['NOUN', 'VERB']
>>> pos['ideas']#we have to supply a parameter which can be used to create the default value, e.g. int, float, str, list, dict, tuple.

pos = defaultdict(lambda: 'NOUN')
pos['colorless'] = 'ADJ'
pos['blog']

counts = defaultdict(int) #invering a dictionary
>>> for word in nltk.corpus.gutenberg.words('milton-paradise.txt'):
...     counts[word] += 1
...
>>> [key for (key, value) in counts.items() if value == 32]

from collections import defaultdict    #We begin by initializing an empty defaultdict, then process each part-of-speech tag in the text. If the tag hasn't been seen before, it will have a zero count by default. Each time we encounter a tag, we increment its count using the += operator.
>>> counts = defaultdict(int)
>>> from nltk.corpus import brown
>>> for (word, tag) in brown.tagged_words(categories='news', tagset='universal'):
...     counts[tag] += 1

counts['NOUN']

sorted(counts)

nltk.download('words')
last_letters = defaultdict(list)
words = nltk.corpus.words.words('en')
for word in words:
    key = word[-2:]                 #start index:end index(startfrom right to left with negative values)-2 means last 2 letters
    last_letters[key].append(word)
last_letters['ly']

#   An anagram is a word or phrase formed by rearranging the letters of a different word or phrase
anagrams = defaultdict(list)
for word in words:
    key = ''.join(sorted(word))
    anagrams[key].append(word)
anagrams['aeilnrt']







