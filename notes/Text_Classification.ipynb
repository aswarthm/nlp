{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "92d68fcf",
      "metadata": {
        "id": "92d68fcf"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import names\n",
        "def gender_stats(filename:str):\n",
        "    dataset_lenght = len(names.words(filename))\n",
        "    first_10_names = names.words(filename)[:10]\n",
        "    last_letters = [name[-1] for name in names.words(filename)]\n",
        "    last_letter_freq = nltk.FreqDist(last_letters)\n",
        "\n",
        "    print(f'Dataset lenght is: {dataset_lenght} \\nThe first names of the dataset are: {first_10_names} \\nLast letters of the names of this dataset are: {last_letter_freq.most_common(5)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "d51862f2",
      "metadata": {
        "id": "d51862f2",
        "outputId": "b357aeaa-4c6b-4eda-8f33-875f8c71c18b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset lenght is: 5001 \n",
            "The first names of the dataset are: ['Abagael', 'Abagail', 'Abbe', 'Abbey', 'Abbi', 'Abbie', 'Abby', 'Abigael', 'Abigail', 'Abigale'] \n",
            "Last letters of the names of this dataset are: [('a', 1773), ('e', 1432), ('y', 461), ('n', 386), ('i', 317)]\n"
          ]
        }
      ],
      "source": [
        "#By using this text classifier we will demonstrate that male and female names have some distinctive characteristics. Names ending in a, e, and i are likely to be female names\n",
        "gender_stats(\"female.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "caab3548",
      "metadata": {
        "id": "caab3548",
        "outputId": "5ac08d90-a1dc-43ac-f726-cfdd490e15d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset lenght is: 2943 \n",
            "The first names of the dataset are: ['Aamir', 'Aaron', 'Abbey', 'Abbie', 'Abbot', 'Abbott', 'Abby', 'Abdel', 'Abdul', 'Abdulkarim'] \n",
            "Last letters of the names of this dataset are: [('n', 478), ('e', 468), ('y', 332), ('s', 230), ('d', 228)]\n"
          ]
        }
      ],
      "source": [
        "gender_stats(\"male.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "092267e0",
      "metadata": {
        "id": "092267e0",
        "outputId": "822634ff-92a8-4fdd-d803-ec35c37181bf",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.77\n",
            "Most Informative Features\n",
            "             last_letter = 'k'              male : female =     43.0 : 1.0\n",
            "             last_letter = 'a'            female : male   =     38.8 : 1.0\n",
            "             last_letter = 'f'              male : female =     16.6 : 1.0\n",
            "             last_letter = 'p'              male : female =     12.5 : 1.0\n",
            "             last_letter = 'v'              male : female =     11.2 : 1.0\n",
            "             last_letter = 'd'              male : female =      9.5 : 1.0\n",
            "             last_letter = 'm'              male : female =      8.6 : 1.0\n",
            "             last_letter = 'o'              male : female =      8.1 : 1.0\n",
            "             last_letter = 'r'              male : female =      6.8 : 1.0\n",
            "             last_letter = 'z'              male : female =      5.6 : 1.0\n",
            "             last_letter = 'w'              male : female =      5.4 : 1.0\n",
            "             last_letter = 'g'              male : female =      5.2 : 1.0\n",
            "             last_letter = 't'              male : female =      4.1 : 1.0\n",
            "             last_letter = 's'              male : female =      4.0 : 1.0\n",
            "             last_letter = 'j'              male : female =      3.9 : 1.0\n",
            "             last_letter = 'i'            female : male   =      3.7 : 1.0\n",
            "             last_letter = 'u'              male : female =      3.5 : 1.0\n",
            "             last_letter = 'b'              male : female =      3.5 : 1.0\n",
            "             last_letter = 'n'              male : female =      2.1 : 1.0\n",
            "             last_letter = 'l'              male : female =      1.8 : 1.0\n",
            "             last_letter = 'e'            female : male   =      1.8 : 1.0\n",
            "             last_letter = 'x'              male : female =      1.7 : 1.0\n",
            "             last_letter = 'h'              male : female =      1.5 : 1.0\n",
            "             last_letter = 'y'              male : female =      1.3 : 1.0\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "#In the above example, we defined a feature extractor function that returns the last letter of a given name.\n",
        "#We used this function to extract the features from the names corpus and trained a Naive Bayes classifier.\n",
        "from nltk.corpus import names\n",
        "import random\n",
        "\n",
        "def gender_features(word):\n",
        "    return {'last_letter': word[-1]}\n",
        "\n",
        "# preparing a list of examples and corresponding class labels.\n",
        "names = ([(name, 'male') for name in names.words('male.txt')] +\n",
        "         [(name, 'female') for name in names.words('female.txt')])\n",
        "random.shuffle(names)\n",
        "\n",
        "# we use the feature extractor to process the names data.\n",
        "featuresets = [(gender_features(n), g) for (n,g) in names]\n",
        "\n",
        "# Divide the resulting list of feature\n",
        "# sets into a training set and a test set.\n",
        "train_set, test_set = featuresets[500:], featuresets[:500]\n",
        "\n",
        "# The training set is used to\n",
        "# train a new \"naive Bayes\" classifier.\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "print(nltk.classify.accuracy(classifier, test_set))\n",
        "print(classifier.show_most_informative_features(26))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "b25edf5e",
      "metadata": {
        "id": "b25edf5e",
        "outputId": "d1240ba6-1085-49f6-b391-80680d96a8d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "female\n"
          ]
        }
      ],
      "source": [
        "print(classifier.classify(gender_features('mahavir')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "120e99e2",
      "metadata": {
        "id": "120e99e2",
        "outputId": "d9be0a3c-b4a2-4abc-e309-3b8a442cbfce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'female'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier.classify(gender_features('Trinity'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "9ee8b39f",
      "metadata": {
        "id": "9ee8b39f",
        "outputId": "1b95412c-4611-491f-d7c3-e4ae092ff97a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'first_letter': 'j',\n",
              " 'last_letter': 'n',\n",
              " 'count(a)': 0,\n",
              " 'has(a)': False,\n",
              " 'count(b)': 0,\n",
              " 'has(b)': False,\n",
              " 'count(c)': 0,\n",
              " 'has(c)': False,\n",
              " 'count(d)': 0,\n",
              " 'has(d)': False,\n",
              " 'count(e)': 0,\n",
              " 'has(e)': False,\n",
              " 'count(f)': 0,\n",
              " 'has(f)': False,\n",
              " 'count(g)': 0,\n",
              " 'has(g)': False,\n",
              " 'count(h)': 1,\n",
              " 'has(h)': True,\n",
              " 'count(i)': 0,\n",
              " 'has(i)': False,\n",
              " 'count(j)': 1,\n",
              " 'has(j)': True,\n",
              " 'count(k)': 0,\n",
              " 'has(k)': False,\n",
              " 'count(l)': 0,\n",
              " 'has(l)': False,\n",
              " 'count(m)': 0,\n",
              " 'has(m)': False,\n",
              " 'count(n)': 1,\n",
              " 'has(n)': True,\n",
              " 'count(o)': 1,\n",
              " 'has(o)': True,\n",
              " 'count(p)': 0,\n",
              " 'has(p)': False,\n",
              " 'count(q)': 0,\n",
              " 'has(q)': False,\n",
              " 'count(r)': 0,\n",
              " 'has(r)': False,\n",
              " 'count(s)': 0,\n",
              " 'has(s)': False,\n",
              " 'count(t)': 0,\n",
              " 'has(t)': False,\n",
              " 'count(u)': 0,\n",
              " 'has(u)': False,\n",
              " 'count(v)': 0,\n",
              " 'has(v)': False,\n",
              " 'count(w)': 0,\n",
              " 'has(w)': False,\n",
              " 'count(x)': 0,\n",
              " 'has(x)': False,\n",
              " 'count(y)': 0,\n",
              " 'has(y)': False,\n",
              " 'count(z)': 0,\n",
              " 'has(z)': False}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#However, there are usually limits to the number of features that you should use with a given learning algorithm — if you provide too many features, then the algorithm will have a higher chance of relying on idiosyncrasies of your training data that don't generalize well to new examples. This problem is known as overfitting\n",
        "def gender_features2(name):\n",
        "    features = {}\n",
        "    features[\"first_letter\"] = name[0].lower()\n",
        "    features[\"last_letter\"] = name[-1].lower()\n",
        "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
        "        features[\"count({})\".format(letter)] = name.lower().count(letter)\n",
        "        features[\"has({})\".format(letter)] = (letter in name.lower())\n",
        "    return features\n",
        "gender_features2('John')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "b480c0bd",
      "metadata": {
        "id": "b480c0bd",
        "outputId": "7499a980-3c92-4592-9378-e6bb77b3f2e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.786\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'female'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Observer 1%lower accuracy than above due to overfitting\n",
        "from nltk.corpus import names\n",
        "labeled_names = ([(name, 'male') for name in names.words('male.txt')] + [(name, 'female') for name in names.words('female.txt')])\n",
        "import random\n",
        "random.shuffle(labeled_names)\n",
        "featuresets = [(gender_features2(n), gender) for (n, gender) in labeled_names]\n",
        "train_set, test_set = featuresets[500:], featuresets[:500]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, test_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "fbd96646",
      "metadata": {
        "id": "fbd96646"
      },
      "outputs": [],
      "source": [
        "#Once an initial set of features has been chosen, a very productive method for refining the feature set is error analysis. First, we select a development set, containing the corpus data for creating the model.\n",
        "#This development set is then subdivided into the training set and the dev-test set.\n",
        "train_names = labeled_names[1500:]\n",
        "devtest_names = labeled_names[500:1500]\n",
        "test_names = labeled_names[:500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "821d6119",
      "metadata": {
        "id": "821d6119",
        "outputId": "89d0b8e3-870b-4c58-b71b-4715562cb941"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.753\n"
          ]
        }
      ],
      "source": [
        "train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
        "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
        "test_set = [(gender_features(n), gender) for (n, gender) in test_names]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, devtest_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a74277c7",
      "metadata": {
        "id": "a74277c7",
        "outputId": "f2ee8b8f-e98a-4702-d651-8a16c338cfa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "correct=female   guess=male     name=Aeriell                       \n",
            "correct=female   guess=male     name=Aidan                         \n",
            "correct=female   guess=male     name=Alyson                        \n",
            "correct=female   guess=male     name=Anais                         \n",
            "correct=female   guess=male     name=Ardis                         \n",
            "correct=female   guess=male     name=Averyl                        \n",
            "correct=female   guess=male     name=Babs                          \n",
            "correct=female   guess=male     name=Berget                        \n",
            "correct=female   guess=male     name=Bette-Ann                     \n",
            "correct=female   guess=male     name=Brandais                      \n",
            "correct=female   guess=male     name=Brear                         \n",
            "correct=female   guess=male     name=Caitrin                       \n",
            "correct=female   guess=male     name=Carilyn                       \n",
            "correct=female   guess=male     name=Carmen                        \n",
            "correct=female   guess=male     name=Carolin                       \n",
            "correct=female   guess=male     name=Caryn                         \n",
            "correct=female   guess=male     name=Cathrin                       \n",
            "correct=female   guess=male     name=Celestyn                      \n",
            "correct=female   guess=male     name=Charmian                      \n",
            "correct=female   guess=male     name=Cher                          \n",
            "correct=female   guess=male     name=Christabel                    \n",
            "correct=female   guess=male     name=Christel                      \n",
            "correct=female   guess=male     name=Christen                      \n",
            "correct=female   guess=male     name=Cindelyn                      \n",
            "correct=female   guess=male     name=Clem                          \n",
            "correct=female   guess=male     name=Cloris                        \n",
            "correct=female   guess=male     name=Coreen                        \n",
            "correct=female   guess=male     name=Coriss                        \n",
            "correct=female   guess=male     name=Cybal                         \n",
            "correct=female   guess=male     name=Dallas                        \n",
            "correct=female   guess=male     name=Daloris                       \n",
            "correct=female   guess=male     name=Darb                          \n",
            "correct=female   guess=male     name=Darell                        \n",
            "correct=female   guess=male     name=Daveen                        \n",
            "correct=female   guess=male     name=Devon                         \n",
            "correct=female   guess=male     name=Diann                         \n",
            "correct=female   guess=male     name=Dion                          \n",
            "correct=female   guess=male     name=Dolores                       \n",
            "correct=female   guess=male     name=Dorcas                        \n",
            "correct=female   guess=male     name=Dyan                          \n",
            "correct=female   guess=male     name=Edin                          \n",
            "correct=female   guess=male     name=Eleanor                       \n",
            "correct=female   guess=male     name=Estell                        \n",
            "correct=female   guess=male     name=Ethelyn                       \n",
            "correct=female   guess=male     name=Evelyn                        \n",
            "correct=female   guess=male     name=Flower                        \n",
            "correct=female   guess=male     name=Frances                       \n",
            "correct=female   guess=male     name=Gates                         \n",
            "correct=female   guess=male     name=Gertrudis                     \n",
            "correct=female   guess=male     name=Glyn                          \n",
            "correct=female   guess=male     name=Grissel                       \n",
            "correct=female   guess=male     name=Harriet                       \n",
            "correct=female   guess=male     name=Hazel                         \n",
            "correct=female   guess=male     name=Honor                         \n",
            "correct=female   guess=male     name=Ines                          \n",
            "correct=female   guess=male     name=Ingeberg                      \n",
            "correct=female   guess=male     name=Ingrid                        \n",
            "correct=female   guess=male     name=Isabeau                       \n",
            "correct=female   guess=male     name=Isador                        \n",
            "correct=female   guess=male     name=Isis                          \n",
            "correct=female   guess=male     name=Janot                         \n",
            "correct=female   guess=male     name=Jean                          \n",
            "correct=female   guess=male     name=Jill                          \n",
            "correct=female   guess=male     name=Jo                            \n",
            "correct=female   guess=male     name=Jo Ann                        \n",
            "correct=female   guess=male     name=Jordain                       \n",
            "correct=female   guess=male     name=Josselyn                      \n",
            "correct=female   guess=male     name=Justin                        \n",
            "correct=female   guess=male     name=Kaitlyn                       \n",
            "correct=female   guess=male     name=Karylin                       \n",
            "correct=female   guess=male     name=Katheleen                     \n",
            "correct=female   guess=male     name=Kathlin                       \n",
            "correct=female   guess=male     name=Keriann                       \n",
            "correct=female   guess=male     name=Kerrill                       \n",
            "correct=female   guess=male     name=Koo                           \n",
            "correct=female   guess=male     name=Kristien                      \n",
            "correct=female   guess=male     name=Lilas                         \n",
            "correct=female   guess=male     name=Lillian                       \n",
            "correct=female   guess=male     name=Linell                        \n",
            "correct=female   guess=male     name=Loralyn                       \n",
            "correct=female   guess=male     name=Lyndell                       \n",
            "correct=female   guess=male     name=Lynnett                       \n",
            "correct=female   guess=male     name=Madelin                       \n",
            "correct=female   guess=male     name=Manon                         \n",
            "correct=female   guess=male     name=Marabel                       \n",
            "correct=female   guess=male     name=Marieann                      \n",
            "correct=female   guess=male     name=Marit                         \n",
            "correct=female   guess=male     name=Marleen                       \n",
            "correct=female   guess=male     name=Maryann                       \n",
            "correct=female   guess=male     name=Maryellen                     \n",
            "correct=female   guess=male     name=Marys                         \n",
            "correct=female   guess=male     name=Maud                          \n",
            "correct=female   guess=male     name=Maureen                       \n",
            "correct=female   guess=male     name=Meghann                       \n",
            "correct=female   guess=male     name=Mehetabel                     \n",
            "correct=female   guess=male     name=Mellicent                     \n",
            "correct=female   guess=male     name=Mellisent                     \n",
            "correct=female   guess=male     name=Meris                         \n",
            "correct=female   guess=male     name=Milissent                     \n",
            "correct=female   guess=male     name=Miriam                        \n",
            "correct=female   guess=male     name=Muriel                        \n",
            "correct=female   guess=male     name=Nanon                         \n",
            "correct=female   guess=male     name=Nert                          \n",
            "correct=female   guess=male     name=Noel                          \n",
            "correct=female   guess=male     name=Orel                          \n",
            "correct=female   guess=male     name=Pegeen                        \n",
            "correct=female   guess=male     name=Piper                         \n",
            "correct=female   guess=male     name=Pru                           \n",
            "correct=female   guess=male     name=Raf                           \n",
            "correct=female   guess=male     name=Rosario                       \n",
            "correct=female   guess=male     name=Roseann                       \n",
            "correct=female   guess=male     name=Rozalin                       \n",
            "correct=female   guess=male     name=Sal                           \n",
            "correct=female   guess=male     name=Sharyl                        \n",
            "correct=female   guess=male     name=Sheila-Kathryn                \n",
            "correct=female   guess=male     name=Suellen                       \n",
            "correct=female   guess=male     name=Tatum                         \n",
            "correct=female   guess=male     name=Tim                           \n",
            "correct=female   guess=male     name=Willyt                        \n",
            "correct=female   guess=male     name=Yoko                          \n",
            "correct=male     guess=female   name=Abe                           \n",
            "correct=male     guess=female   name=Alex                          \n",
            "correct=male     guess=female   name=Allah                         \n",
            "correct=male     guess=female   name=Amory                         \n",
            "correct=male     guess=female   name=Andrey                        \n",
            "correct=male     guess=female   name=Antone                        \n",
            "correct=male     guess=female   name=Archy                         \n",
            "correct=male     guess=female   name=Aube                          \n",
            "correct=male     guess=female   name=Avery                         \n",
            "correct=male     guess=female   name=Barri                         \n",
            "correct=male     guess=female   name=Barrie                        \n",
            "correct=male     guess=female   name=Barth                         \n",
            "correct=male     guess=female   name=Benny                         \n",
            "correct=male     guess=female   name=Berkie                        \n",
            "correct=male     guess=female   name=Broddie                       \n",
            "correct=male     guess=female   name=Buddy                         \n",
            "correct=male     guess=female   name=Carlie                        \n",
            "correct=male     guess=female   name=Case                          \n",
            "correct=male     guess=female   name=Casey                         \n",
            "correct=male     guess=female   name=Chane                         \n",
            "correct=male     guess=female   name=Charlie                       \n",
            "correct=male     guess=female   name=Chauncey                      \n",
            "correct=male     guess=female   name=Christy                       \n",
            "correct=male     guess=female   name=Clare                         \n",
            "correct=male     guess=female   name=Corby                         \n",
            "correct=male     guess=female   name=Corky                         \n",
            "correct=male     guess=female   name=Corrie                        \n",
            "correct=male     guess=female   name=Cortese                       \n",
            "correct=male     guess=female   name=Cory                          \n",
            "correct=male     guess=female   name=Dale                          \n",
            "correct=male     guess=female   name=Daryle                        \n",
            "correct=male     guess=female   name=Davie                         \n",
            "correct=male     guess=female   name=Dougie                        \n",
            "correct=male     guess=female   name=Drake                         \n",
            "correct=male     guess=female   name=Edie                          \n",
            "correct=male     guess=female   name=Ferdie                        \n",
            "correct=male     guess=female   name=Fletch                        \n",
            "correct=male     guess=female   name=Fox                           \n",
            "correct=male     guess=female   name=Frankie                       \n",
            "correct=male     guess=female   name=Freddy                        \n",
            "correct=male     guess=female   name=Gale                          \n",
            "correct=male     guess=female   name=Gerri                         \n",
            "correct=male     guess=female   name=Godfree                       \n",
            "correct=male     guess=female   name=Grace                         \n",
            "correct=male     guess=female   name=Hadleigh                      \n",
            "correct=male     guess=female   name=Hale                          \n",
            "correct=male     guess=female   name=Haley                         \n",
            "correct=male     guess=female   name=Heath                         \n",
            "correct=male     guess=female   name=Henri                         \n",
            "correct=male     guess=female   name=Ira                           \n",
            "correct=male     guess=female   name=Irvine                        \n",
            "correct=male     guess=female   name=Isadore                       \n",
            "correct=male     guess=female   name=Jae                           \n",
            "correct=male     guess=female   name=Jamey                         \n",
            "correct=male     guess=female   name=Jeremy                        \n",
            "correct=male     guess=female   name=Jerome                        \n",
            "correct=male     guess=female   name=Jerrie                        \n",
            "correct=male     guess=female   name=Jimmy                         \n",
            "correct=male     guess=female   name=Jodi                          \n",
            "correct=male     guess=female   name=Joey                          \n",
            "correct=male     guess=female   name=Jorge                         \n",
            "correct=male     guess=female   name=Jose                          \n",
            "correct=male     guess=female   name=Kennedy                       \n",
            "correct=male     guess=female   name=Kingsley                      \n",
            "correct=male     guess=female   name=Kirby                         \n",
            "correct=male     guess=female   name=Lyle                          \n",
            "correct=male     guess=female   name=Mahesh                        \n",
            "correct=male     guess=female   name=Marlowe                       \n",
            "correct=male     guess=female   name=Marve                         \n",
            "correct=male     guess=female   name=Mendie                        \n",
            "correct=male     guess=female   name=Merry                         \n",
            "correct=male     guess=female   name=Moe                           \n",
            "correct=male     guess=female   name=Moishe                        \n",
            "correct=male     guess=female   name=Morry                         \n",
            "correct=male     guess=female   name=Neddie                        \n",
            "correct=male     guess=female   name=Neville                       \n",
            "correct=male     guess=female   name=Odie                          \n",
            "correct=male     guess=female   name=Orbadiah                      \n",
            "correct=male     guess=female   name=Pascale                       \n",
            "correct=male     guess=female   name=Patrice                       \n",
            "correct=male     guess=female   name=Perry                         \n",
            "correct=male     guess=female   name=Petey                         \n",
            "correct=male     guess=female   name=Pooh                          \n",
            "correct=male     guess=female   name=Radcliffe                     \n",
            "correct=male     guess=female   name=Rafe                          \n",
            "correct=male     guess=female   name=Ricki                         \n",
            "correct=male     guess=female   name=Riley                         \n",
            "correct=male     guess=female   name=Rodolph                       \n",
            "correct=male     guess=female   name=Ronnie                        \n",
            "correct=male     guess=female   name=Salomone                      \n",
            "correct=male     guess=female   name=Samuele                       \n",
            "correct=male     guess=female   name=Scotty                        \n",
            "correct=male     guess=female   name=See                           \n",
            "correct=male     guess=female   name=Selby                         \n",
            "correct=male     guess=female   name=Seth                          \n",
            "correct=male     guess=female   name=Shane                         \n",
            "correct=male     guess=female   name=Shea                          \n",
            "correct=male     guess=female   name=Shorty                        \n",
            "correct=male     guess=female   name=Shurlocke                     \n",
            "correct=male     guess=female   name=Sky                           \n",
            "correct=male     guess=female   name=Slade                         \n",
            "correct=male     guess=female   name=Sonny                         \n",
            "correct=male     guess=female   name=Stanleigh                     \n",
            "correct=male     guess=female   name=Stearne                       \n",
            "correct=male     guess=female   name=Tanny                         \n",
            "correct=male     guess=female   name=Tate                          \n",
            "correct=male     guess=female   name=Tedie                         \n",
            "correct=male     guess=female   name=Thane                         \n",
            "correct=male     guess=female   name=Thorndike                     \n",
            "correct=male     guess=female   name=Toddie                        \n",
            "correct=male     guess=female   name=Tome                          \n",
            "correct=male     guess=female   name=Tommie                        \n",
            "correct=male     guess=female   name=Torrey                        \n",
            "correct=male     guess=female   name=Towny                         \n",
            "correct=male     guess=female   name=Tucky                         \n",
            "correct=male     guess=female   name=Tulley                        \n",
            "correct=male     guess=female   name=Voltaire                      \n",
            "correct=male     guess=female   name=Waverley                      \n",
            "correct=male     guess=female   name=Whitby                        \n",
            "correct=male     guess=female   name=Wittie                        \n",
            "correct=male     guess=female   name=Witty                         \n",
            "correct=male     guess=female   name=Yancey                        \n",
            "correct=male     guess=female   name=Yule                          \n",
            "correct=male     guess=female   name=Yuri                          \n",
            "correct=male     guess=female   name=Zackariah                     \n",
            "correct=male     guess=female   name=Zedekiah                      \n",
            "correct=male     guess=female   name=Zolly                         \n"
          ]
        }
      ],
      "source": [
        "#Using the dev-test set, we can generate a list of the errors that the classifier makes when predicting name genders:\n",
        "errors = []\n",
        "for (name, tag) in devtest_names:\n",
        "    guess = classifier.classify(gender_features(name))\n",
        "    if guess != tag:\n",
        "        errors.append( (tag, guess, name) )\n",
        "for (tag, guess, name) in sorted(errors):\n",
        "    print('correct={:<8} guess={:<8s} name={:<30}'.format(tag, guess, name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a8751115",
      "metadata": {
        "id": "a8751115"
      },
      "outputs": [],
      "source": [
        "#errors makes it clear that some suffixes that are more than one letter can be indicative of name genders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1ecfb7cd",
      "metadata": {
        "id": "1ecfb7cd",
        "outputId": "54974cb7-4757-458f-8063-a4a38dd6751a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.772\n"
          ]
        }
      ],
      "source": [
        "#adjust our feature extractor to include features for two-letter suffixes:\n",
        "def gender_features(word):\n",
        "    return {'suffix1': word[-1:],'suffix2': word[-2:]}\n",
        "train_set = [(gender_features(n), gender) for (n, gender) in train_names]\n",
        "devtest_set = [(gender_features(n), gender) for (n, gender) in devtest_names]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, devtest_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b7843a8a",
      "metadata": {
        "id": "b7843a8a",
        "outputId": "c2141c00-d851-4a65-cced-126cc2f283f2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package movie_reviews to\n",
            "[nltk_data]     C:\\Users\\maswa\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#Document classification - positive or negative\n",
        "nltk.download('movie_reviews')\n",
        "from nltk.corpus import movie_reviews\n",
        "documents = [(list(movie_reviews.words(fileid)), category)\n",
        "for category in movie_reviews.categories()\n",
        "for fileid in movie_reviews.fileids(category)]\n",
        "random.shuffle(documents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "23160e18",
      "metadata": {
        "id": "23160e18",
        "outputId": "e96d0151-0a01-4a1f-b020-e78be0f701de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'contains(,)': True, 'contains(the)': True, 'contains(.)': True, 'contains(a)': True, 'contains(and)': True, 'contains(of)': True, 'contains(to)': True, \"contains(')\": True, 'contains(is)': True, 'contains(in)': True, 'contains(s)': True, 'contains(\")': True, 'contains(it)': True, 'contains(that)': True, 'contains(-)': True, 'contains())': True, 'contains(()': True, 'contains(as)': True, 'contains(with)': True, 'contains(for)': True, 'contains(his)': True, 'contains(this)': True, 'contains(film)': False, 'contains(i)': False, 'contains(he)': True, 'contains(but)': True, 'contains(on)': True, 'contains(are)': True, 'contains(t)': False, 'contains(by)': True, 'contains(be)': True, 'contains(one)': True, 'contains(movie)': True, 'contains(an)': True, 'contains(who)': True, 'contains(not)': True, 'contains(you)': True, 'contains(from)': True, 'contains(at)': False, 'contains(was)': False, 'contains(have)': True, 'contains(they)': True, 'contains(has)': True, 'contains(her)': False, 'contains(all)': True, 'contains(?)': False, 'contains(there)': True, 'contains(like)': True, 'contains(so)': False, 'contains(out)': True, 'contains(about)': True, 'contains(up)': False, 'contains(more)': False, 'contains(what)': True, 'contains(when)': True, 'contains(which)': True, 'contains(or)': False, 'contains(she)': True, 'contains(their)': False, 'contains(:)': True, 'contains(some)': False, 'contains(just)': True, 'contains(can)': False, 'contains(if)': True, 'contains(we)': False, 'contains(him)': True, 'contains(into)': True, 'contains(even)': False, 'contains(only)': True, 'contains(than)': False, 'contains(no)': False, 'contains(good)': False, 'contains(time)': False, 'contains(most)': True, 'contains(its)': False, 'contains(will)': True, 'contains(story)': False, 'contains(would)': False, 'contains(been)': False, 'contains(much)': False, 'contains(character)': False, 'contains(also)': True, 'contains(get)': True, 'contains(other)': True, 'contains(do)': True, 'contains(two)': True, 'contains(well)': True, 'contains(them)': True, 'contains(very)': True, 'contains(characters)': False, 'contains(;)': False, 'contains(first)': False, 'contains(--)': True, 'contains(after)': False, 'contains(see)': False, 'contains(!)': True, 'contains(way)': True, 'contains(because)': False, 'contains(make)': True, 'contains(life)': False, 'contains(off)': False, 'contains(too)': False, 'contains(any)': False, 'contains(does)': False, 'contains(really)': False, 'contains(had)': False, 'contains(while)': True, 'contains(films)': False, 'contains(how)': True, 'contains(plot)': True, 'contains(little)': True, 'contains(where)': True, 'contains(people)': False, 'contains(over)': False, 'contains(could)': False, 'contains(then)': True, 'contains(me)': True, 'contains(scene)': True, 'contains(man)': False, 'contains(bad)': False, 'contains(my)': False, 'contains(never)': True, 'contains(being)': False, 'contains(best)': True, 'contains(these)': False, 'contains(don)': False, 'contains(new)': False, 'contains(doesn)': False, 'contains(scenes)': False, 'contains(many)': True, 'contains(director)': False, 'contains(such)': False, 'contains(know)': False, 'contains(were)': False, 'contains(movies)': True, 'contains(through)': False, 'contains(here)': True, 'contains(action)': True, 'contains(great)': True, 'contains(re)': True, 'contains(another)': False, 'contains(love)': False, 'contains(go)': False, 'contains(made)': False, 'contains(us)': True, 'contains(big)': False, 'contains(end)': False, 'contains(something)': False, 'contains(back)': False, 'contains(*)': True, 'contains(still)': False, 'contains(world)': True, 'contains(seems)': False, 'contains(work)': False, 'contains(those)': False, 'contains(makes)': False, 'contains(now)': False, 'contains(before)': False, 'contains(however)': True, 'contains(between)': True, 'contains(few)': False, 'contains(/)': False, 'contains(down)': False, 'contains(every)': False, 'contains(though)': False, 'contains(better)': False, 'contains(real)': False, 'contains(audience)': False, 'contains(enough)': False, 'contains(seen)': False, 'contains(take)': False, 'contains(around)': False, 'contains(both)': False, 'contains(going)': False, 'contains(year)': False, 'contains(performance)': False, 'contains(why)': False, 'contains(should)': False, 'contains(role)': False, 'contains(isn)': False, 'contains(same)': True, 'contains(old)': False, 'contains(gets)': True, 'contains(your)': False, 'contains(may)': False, 'contains(things)': True, 'contains(think)': False, 'contains(years)': False, 'contains(last)': False, 'contains(comedy)': True, 'contains(funny)': True, 'contains(actually)': True, 'contains(ve)': False, 'contains(long)': False, 'contains(look)': True, 'contains(almost)': False, 'contains(own)': True, 'contains(thing)': False, 'contains(fact)': False, 'contains(nothing)': False, 'contains(say)': False, 'contains(right)': False, 'contains(john)': False, 'contains(although)': False, 'contains(played)': True, 'contains(find)': False, 'contains(script)': False, 'contains(come)': False, 'contains(ever)': True, 'contains(cast)': False, 'contains(since)': False, 'contains(did)': False, 'contains(star)': False, 'contains(plays)': False, 'contains(young)': False, 'contains(show)': False, 'contains(comes)': False, 'contains(m)': False, 'contains(part)': False, 'contains(original)': False, 'contains(actors)': False, 'contains(screen)': True, 'contains(without)': False, 'contains(again)': False, 'contains(acting)': False, 'contains(three)': False, 'contains(day)': True, 'contains(each)': True, 'contains(point)': False, 'contains(lot)': False, 'contains(least)': True, 'contains(takes)': False, 'contains(guy)': True, 'contains(quite)': False, 'contains(himself)': False, 'contains(away)': False, 'contains(during)': False, 'contains(family)': False, 'contains(effects)': False, 'contains(course)': True, 'contains(goes)': False, 'contains(minutes)': False, 'contains(interesting)': False, 'contains(might)': False, 'contains(far)': False, 'contains(high)': False, 'contains(rather)': False, 'contains(once)': True, 'contains(must)': False, 'contains(anything)': False, 'contains(place)': True, 'contains(set)': False, 'contains(yet)': False, 'contains(watch)': True, 'contains(d)': False, 'contains(making)': True, 'contains(our)': False, 'contains(wife)': True, 'contains(hard)': False, 'contains(always)': False, 'contains(fun)': True, 'contains(didn)': False, 'contains(ll)': False, 'contains(seem)': False, 'contains(special)': False, 'contains(bit)': False, 'contains(times)': False, 'contains(trying)': False, 'contains(hollywood)': False, 'contains(instead)': False, 'contains(give)': False, 'contains(want)': False, 'contains(picture)': False, 'contains(kind)': True, 'contains(american)': False, 'contains(job)': False, 'contains(sense)': False, 'contains(woman)': True, 'contains(home)': False, 'contains(having)': False, 'contains(series)': True, 'contains(actor)': False, 'contains(probably)': False, 'contains(help)': True, 'contains(half)': False, 'contains(along)': True, 'contains(men)': False, 'contains(everything)': True, 'contains(pretty)': False, 'contains(becomes)': False, 'contains(sure)': False, 'contains(black)': False, 'contains(together)': False, 'contains(dialogue)': False, 'contains(money)': False, 'contains(become)': False, 'contains(gives)': False, 'contains(given)': False, 'contains(looking)': False, 'contains(whole)': False, 'contains(watching)': False, 'contains(father)': False, 'contains(`)': False, 'contains(feel)': False, 'contains(everyone)': False, 'contains(music)': False, 'contains(wants)': False, 'contains(sex)': False, 'contains(less)': False, 'contains(done)': False, 'contains(horror)': False, 'contains(got)': True, 'contains(death)': False, 'contains(perhaps)': False, 'contains(city)': False, 'contains(next)': False, 'contains(especially)': True, 'contains(play)': False, 'contains(girl)': False, 'contains(mind)': False, 'contains(10)': False, 'contains(moments)': False, 'contains(looks)': True, 'contains(completely)': False, 'contains(2)': False, 'contains(reason)': False, 'contains(mother)': False, 'contains(whose)': False, 'contains(line)': False, 'contains(night)': False, 'contains(human)': False, 'contains(until)': False, 'contains(rest)': False, 'contains(performances)': False, 'contains(different)': False, 'contains(evil)': False, 'contains(small)': False, 'contains(james)': False, 'contains(simply)': False, 'contains(couple)': False, 'contains(put)': False, 'contains(let)': False, 'contains(anyone)': False, 'contains(ending)': False, 'contains(case)': False, 'contains(several)': False, 'contains(dead)': False, 'contains(michael)': False, 'contains(left)': False, 'contains(thought)': False, 'contains(school)': False, 'contains(shows)': False, 'contains(humor)': False, 'contains(true)': False, 'contains(lost)': False, 'contains(written)': False, 'contains(itself)': False, 'contains(friend)': False, 'contains(entire)': False, 'contains(getting)': True, 'contains(town)': False, 'contains(turns)': False, 'contains(soon)': False, 'contains(someone)': False, 'contains(second)': False, 'contains(main)': False, 'contains(stars)': False, 'contains(found)': False, 'contains(use)': False, 'contains(problem)': False, 'contains(friends)': True, 'contains(tv)': False, 'contains(top)': True, 'contains(name)': False, 'contains(begins)': False, 'contains(called)': False, 'contains(based)': False, 'contains(comic)': False, 'contains(david)': False, 'contains(head)': False, 'contains(else)': False, 'contains(idea)': True, 'contains(either)': False, 'contains(wrong)': True, 'contains(unfortunately)': False, 'contains(later)': False, 'contains(final)': False, 'contains(hand)': False, 'contains(alien)': False, 'contains(house)': False, 'contains(group)': False, 'contains(full)': False, 'contains(used)': True, 'contains(tries)': True, 'contains(often)': True, 'contains(against)': False, 'contains(war)': False, 'contains(sequence)': False, 'contains(keep)': False, 'contains(turn)': False, 'contains(playing)': True, 'contains(boy)': False, 'contains(behind)': False, 'contains(named)': False, 'contains(certainly)': False, 'contains(live)': False, 'contains(believe)': False, 'contains(under)': False, 'contains(works)': False, 'contains(relationship)': False, 'contains(face)': False, 'contains(hour)': False, 'contains(run)': False, 'contains(style)': False, 'contains(said)': False, 'contains(despite)': False, 'contains(person)': False, 'contains(finally)': False, 'contains(shot)': False, 'contains(book)': False, 'contains(doing)': False, 'contains(tell)': False, 'contains(maybe)': False, 'contains(nice)': False, 'contains(son)': False, 'contains(perfect)': False, 'contains(side)': False, 'contains(seeing)': True, 'contains(able)': False, 'contains(finds)': False, 'contains(children)': False, 'contains(days)': False, 'contains(past)': False, 'contains(summer)': False, 'contains(camera)': False, 'contains(won)': False, 'contains(including)': False, 'contains(mr)': False, 'contains(kids)': False, 'contains(lives)': False, 'contains(directed)': False, 'contains(moment)': False, 'contains(game)': False, 'contains(running)': False, 'contains(fight)': True, 'contains(supposed)': False, 'contains(video)': False, 'contains(car)': False, 'contains(matter)': False, 'contains(kevin)': True, 'contains(joe)': False, 'contains(lines)': False, 'contains(worth)': True, 'contains(=)': False, 'contains(daughter)': False, 'contains(earth)': False, 'contains(starts)': False, 'contains(need)': False, 'contains(entertaining)': False, 'contains(white)': False, 'contains(start)': True, 'contains(writer)': False, 'contains(dark)': False, 'contains(short)': False, 'contains(self)': False, 'contains(worst)': False, 'contains(nearly)': False, 'contains(opening)': False, 'contains(try)': False, 'contains(upon)': False, 'contains(care)': False, 'contains(early)': True, 'contains(violence)': False, 'contains(throughout)': False, 'contains(team)': False, 'contains(production)': False, 'contains(example)': False, 'contains(beautiful)': False, 'contains(title)': False, 'contains(exactly)': False, 'contains(jack)': False, 'contains(review)': False, 'contains(major)': False, 'contains(drama)': False, 'contains(&)': False, 'contains(problems)': True, 'contains(sequences)': False, 'contains(obvious)': False, 'contains(version)': False, 'contains(screenplay)': False, 'contains(known)': True, 'contains(killer)': False, 'contains(wasn)': False, 'contains(robert)': False, 'contains(disney)': False, 'contains(already)': False, 'contains(close)': False, 'contains(classic)': False, 'contains(others)': True, 'contains(hit)': False, 'contains(kill)': False, 'contains(deep)': True, 'contains(five)': False, 'contains(order)': False, 'contains(act)': False, 'contains(simple)': False, 'contains(fine)': False, 'contains(themselves)': False, 'contains(heart)': False, 'contains(roles)': False, 'contains(jackie)': True, 'contains(direction)': False, 'contains(eyes)': False, 'contains(four)': False, 'contains(question)': False, 'contains(sort)': False, 'contains(sometimes)': False, 'contains(knows)': False, 'contains(supporting)': False, 'contains(coming)': False, 'contains(voice)': False, 'contains(women)': False, 'contains(truly)': False, 'contains(save)': False, 'contains(jokes)': False, 'contains(computer)': False, 'contains(child)': False, 'contains(o)': False, 'contains(boring)': False, 'contains(tom)': False, 'contains(level)': False, 'contains(1)': False, 'contains(body)': False, 'contains(guys)': False, 'contains(genre)': False, 'contains(brother)': False, 'contains(strong)': False, 'contains(stop)': True, 'contains(room)': False, 'contains(space)': False, 'contains(lee)': False, 'contains(ends)': False, 'contains(beginning)': False, 'contains(ship)': False, 'contains(york)': False, 'contains(attempt)': False, 'contains(thriller)': False, 'contains(scream)': True, 'contains(peter)': False, 'contains(aren)': False, 'contains(husband)': False, 'contains(fiction)': False, 'contains(happens)': False, 'contains(hero)': False, 'contains(novel)': False, 'contains(note)': False, 'contains(hope)': False, 'contains(king)': False, 'contains(yes)': False, 'contains(says)': False, 'contains(tells)': False, 'contains(quickly)': False, 'contains(romantic)': False, 'contains(dog)': False, 'contains(oscar)': False, 'contains(stupid)': False, 'contains(possible)': False, 'contains(saw)': False, 'contains(lead)': True, 'contains(career)': False, 'contains(murder)': False, 'contains(extremely)': False, 'contains(manages)': False, 'contains(god)': False, 'contains(mostly)': False, 'contains(wonder)': False, 'contains(particularly)': False, 'contains(future)': False, 'contains(fans)': False, 'contains(sound)': False, 'contains(worse)': False, 'contains(piece)': False, 'contains(involving)': False, 'contains(de)': False, 'contains(appears)': False, 'contains(planet)': False, 'contains(paul)': False, 'contains(involved)': False, 'contains(mean)': False, 'contains(none)': False, 'contains(taking)': False, 'contains(hours)': False, 'contains(laugh)': True, 'contains(police)': False, 'contains(sets)': False, 'contains(attention)': False, 'contains(co)': False, 'contains(hell)': False, 'contains(eventually)': False, 'contains(single)': False, 'contains(fall)': False, 'contains(falls)': False, 'contains(material)': False, 'contains(emotional)': False, 'contains(power)': False, 'contains(late)': False, 'contains(lack)': False, 'contains(dr)': False, 'contains(van)': False, 'contains(result)': False, 'contains(elements)': False, 'contains(meet)': False, 'contains(smith)': False, 'contains(science)': False, 'contains(experience)': False, 'contains(bring)': False, 'contains(wild)': False, 'contains(living)': False, 'contains(theater)': False, 'contains(interest)': False, 'contains(leads)': False, 'contains(word)': False, 'contains(feature)': False, 'contains(battle)': False, 'contains(girls)': False, 'contains(alone)': False, 'contains(obviously)': False, 'contains(george)': False, 'contains(within)': False, 'contains(usually)': False, 'contains(enjoy)': False, 'contains(guess)': False, 'contains(among)': True, 'contains(taken)': False, 'contains(feeling)': False, 'contains(laughs)': False, 'contains(aliens)': False, 'contains(talk)': True, 'contains(chance)': False, 'contains(talent)': False, 'contains(3)': False, 'contains(middle)': False, 'contains(number)': False, 'contains(easy)': False, 'contains(across)': False, 'contains(needs)': False, 'contains(attempts)': False, 'contains(happen)': False, 'contains(television)': False, 'contains(chris)': False, 'contains(deal)': False, 'contains(poor)': False, 'contains(form)': False, 'contains(girlfriend)': True, 'contains(viewer)': False, 'contains(release)': False, 'contains(killed)': False, 'contains(forced)': False, 'contains(whether)': False, 'contains(wonderful)': False, 'contains(feels)': False, 'contains(oh)': False, 'contains(tale)': False, 'contains(serious)': False, 'contains(expect)': False, 'contains(except)': False, 'contains(light)': False, 'contains(success)': False, 'contains(features)': True, 'contains(premise)': False, 'contains(happy)': False, 'contains(words)': False, 'contains(leave)': False, 'contains(important)': False, 'contains(meets)': False, 'contains(history)': False, 'contains(giving)': False, 'contains(crew)': False, 'contains(type)': False, 'contains(call)': False, 'contains(turned)': False, 'contains(released)': False, 'contains(parents)': False, 'contains(art)': False, 'contains(impressive)': False, 'contains(mission)': False, 'contains(working)': False, 'contains(seemed)': False, 'contains(score)': False, 'contains(told)': False, 'contains(recent)': False, 'contains(robin)': False, 'contains(basically)': False, 'contains(entertainment)': False, 'contains(america)': False, 'contains($)': False, 'contains(surprise)': False, 'contains(apparently)': False, 'contains(easily)': False, 'contains(ryan)': False, 'contains(cool)': False, 'contains(stuff)': False, 'contains(cop)': False, 'contains(change)': False, 'contains(williams)': False, 'contains(crime)': False, 'contains(office)': False, 'contains(parts)': False, 'contains(somehow)': False, 'contains(sequel)': False, 'contains(william)': False, 'contains(cut)': False, 'contains(die)': False, 'contains(jones)': False, 'contains(credits)': False, 'contains(batman)': False, 'contains(suspense)': False, 'contains(brings)': False, 'contains(events)': False, 'contains(reality)': False, 'contains(whom)': False, 'contains(local)': False, 'contains(talking)': False, 'contains(difficult)': True, 'contains(using)': False, 'contains(went)': False, 'contains(writing)': False, 'contains(remember)': False, 'contains(near)': False, 'contains(straight)': False, 'contains(hilarious)': True, 'contains(ago)': False, 'contains(certain)': False, 'contains(ben)': False, 'contains(kid)': False, 'contains(wouldn)': False, 'contains(slow)': True, 'contains(blood)': False, 'contains(mystery)': False, 'contains(complete)': False, 'contains(red)': False, 'contains(popular)': False, 'contains(effective)': False, 'contains(am)': False, 'contains(fast)': True, 'contains(flick)': False, 'contains(due)': False, 'contains(runs)': False, 'contains(gone)': False, 'contains(return)': False, 'contains(presence)': False, 'contains(quality)': False, 'contains(dramatic)': False, 'contains(filmmakers)': False, 'contains(age)': False, 'contains(brothers)': False, 'contains(business)': False, 'contains(general)': False, 'contains(rock)': False, 'contains(sexual)': False, 'contains(present)': False, 'contains(surprisingly)': False, 'contains(anyway)': False, 'contains(uses)': False, 'contains(4)': False, 'contains(personal)': False, 'contains(figure)': False, 'contains(smart)': False, 'contains(ways)': False, 'contains(decides)': False, 'contains(annoying)': False, 'contains(begin)': False, 'contains(couldn)': False, 'contains(somewhat)': False, 'contains(shots)': False, 'contains(rich)': False, 'contains(minute)': False, 'contains(law)': False, 'contains(previous)': False, 'contains(jim)': False, 'contains(successful)': False, 'contains(harry)': False, 'contains(water)': False, 'contains(similar)': False, 'contains(absolutely)': False, 'contains(motion)': False, 'contains(former)': False, 'contains(strange)': False, 'contains(came)': False, 'contains(follow)': False, 'contains(read)': False, 'contains(project)': False, 'contains(million)': True, 'contains(secret)': False, 'contains(starring)': False, 'contains(clear)': False, 'contains(familiar)': False, 'contains(romance)': False, 'contains(intelligent)': False, 'contains(third)': True, 'contains(excellent)': False, 'contains(amazing)': False, 'contains(party)': False, 'contains(budget)': False, 'contains(eye)': False, 'contains(actress)': False, 'contains(prison)': False, 'contains(latest)': False, 'contains(means)': True, 'contains(company)': False, 'contains(towards)': False, 'contains(predictable)': False, 'contains(powerful)': False, 'contains(nor)': False, 'contains(bob)': False, 'contains(beyond)': False, 'contains(visual)': False, 'contains(leaves)': False, 'contains(r)': False, 'contains(nature)': False, 'contains(following)': False, 'contains(villain)': False, 'contains(leaving)': False, 'contains(animated)': False, 'contains(low)': False, 'contains(myself)': False, 'contains(b)': False, 'contains(bill)': False, 'contains(sam)': False, 'contains(filled)': False, 'contains(wars)': False, 'contains(questions)': False, 'contains(cinema)': False, 'contains(message)': False, 'contains(box)': False, 'contains(moving)': True, 'contains(herself)': False, 'contains(country)': False, 'contains(usual)': False, 'contains(martin)': False, 'contains(definitely)': False, 'contains(add)': False, 'contains(large)': False, 'contains(clever)': False, 'contains(create)': False, 'contains(felt)': False, 'contains(stories)': False, 'contains(brilliant)': False, 'contains(ones)': False, 'contains(giant)': False, 'contains(situation)': False, 'contains(murphy)': False, 'contains(break)': False, 'contains(opens)': False, 'contains(scary)': False, 'contains(doubt)': False, 'contains(drug)': True, 'contains(bunch)': False, 'contains(thinking)': False, 'contains(solid)': False, 'contains(effect)': False, 'contains(learn)': False, 'contains(move)': False, 'contains(force)': False, 'contains(potential)': False, 'contains(seriously)': False, 'contains(follows)': False, 'contains(above)': False, 'contains(saying)': False, 'contains(huge)': False, 'contains(class)': False, 'contains(plan)': False, 'contains(agent)': False, 'contains(created)': False, 'contains(unlike)': False, 'contains(pay)': False, 'contains(non)': True, 'contains(married)': False, 'contains(mark)': False, 'contains(sweet)': False, 'contains(perfectly)': False, 'contains(ex)': False, 'contains(realize)': False, 'contains(audiences)': False, 'contains(took)': False, 'contains(decent)': False, 'contains(likely)': False, 'contains(dream)': False, 'contains(view)': False, 'contains(scott)': False, 'contains(subject)': False, 'contains(understand)': False, 'contains(happened)': False, 'contains(enjoyable)': True, 'contains(studio)': False, 'contains(immediately)': False, 'contains(open)': False, 'contains(e)': False, 'contains(points)': False, 'contains(heard)': False, 'contains(viewers)': False, 'contains(cameron)': False, 'contains(truman)': False, 'contains(bruce)': False, 'contains(frank)': False, 'contains(private)': False, 'contains(stay)': False, 'contains(fails)': False, 'contains(impossible)': False, 'contains(cold)': False, 'contains(richard)': False, 'contains(overall)': False, 'contains(merely)': False, 'contains(exciting)': False, 'contains(mess)': False, 'contains(chase)': True, 'contains(free)': False, 'contains(ten)': False, 'contains(neither)': False, 'contains(wanted)': False, 'contains(gun)': True, 'contains(appear)': False, 'contains(carter)': False, 'contains(escape)': False, 'contains(ultimately)': False, 'contains(+)': False, 'contains(fan)': False, 'contains(inside)': False, 'contains(favorite)': False, 'contains(haven)': False, 'contains(modern)': False, 'contains(l)': False, 'contains(wedding)': False, 'contains(stone)': False, 'contains(trek)': False, 'contains(brought)': False, 'contains(trouble)': True, 'contains(otherwise)': False, 'contains(tim)': False, 'contains(5)': False, 'contains(allen)': False, 'contains(bond)': False, 'contains(society)': False, 'contains(liked)': False, 'contains(dumb)': False, 'contains(musical)': False, 'contains(stand)': False, 'contains(political)': False, 'contains(various)': False, 'contains(talented)': False, 'contains(particular)': False, 'contains(west)': False, 'contains(state)': False, 'contains(keeps)': True, 'contains(english)': False, 'contains(silly)': False, 'contains(u)': False, 'contains(situations)': False, 'contains(park)': False, 'contains(teen)': False, 'contains(rating)': False, 'contains(slightly)': False, 'contains(steve)': False, 'contains(truth)': False, 'contains(air)': False, 'contains(element)': False, 'contains(joke)': False, 'contains(spend)': False, 'contains(key)': True, 'contains(biggest)': False, 'contains(members)': False, 'contains(effort)': False, 'contains(government)': False, 'contains(focus)': False, 'contains(eddie)': False, 'contains(soundtrack)': False, 'contains(hands)': False, 'contains(earlier)': False, 'contains(chan)': True, 'contains(purpose)': False, 'contains(today)': True, 'contains(showing)': False, 'contains(memorable)': False, 'contains(six)': False, 'contains(cannot)': False, 'contains(max)': False, 'contains(offers)': False, 'contains(rated)': False, 'contains(mars)': False, 'contains(heavy)': False, 'contains(totally)': False, 'contains(control)': False, 'contains(credit)': False, 'contains(fi)': False, 'contains(woody)': False, 'contains(ideas)': False, 'contains(sci)': False, 'contains(wait)': False, 'contains(sit)': False, 'contains(female)': False, 'contains(ask)': False, 'contains(waste)': False, 'contains(terrible)': False, 'contains(depth)': False, 'contains(simon)': False, 'contains(aspect)': False, 'contains(list)': False, 'contains(mary)': False, 'contains(sister)': False, 'contains(animation)': False, 'contains(entirely)': False, 'contains(fear)': False, 'contains(steven)': False, 'contains(moves)': False, 'contains(actual)': False, 'contains(army)': False, 'contains(british)': False, 'contains(constantly)': False, 'contains(fire)': False, 'contains(convincing)': False, 'contains(setting)': False, 'contains(gave)': False, 'contains(tension)': False, 'contains(street)': False, 'contains(8)': False, 'contains(brief)': True, 'contains(ridiculous)': False, 'contains(cinematography)': False, 'contains(typical)': False, 'contains(nick)': False, 'contains(screenwriter)': False, 'contains(ability)': False, 'contains(spent)': False, 'contains(quick)': True, 'contains(violent)': False, 'contains(atmosphere)': False, 'contains(subtle)': False, 'contains(expected)': False, 'contains(fairly)': True, 'contains(seven)': False, 'contains(killing)': False, 'contains(tone)': False, 'contains(master)': False, 'contains(disaster)': False, 'contains(lots)': False, 'contains(thinks)': False, 'contains(song)': False, 'contains(cheap)': False, 'contains(suddenly)': False, 'contains(background)': False, 'contains(club)': False, 'contains(willis)': False, 'contains(whatever)': False, 'contains(highly)': False, 'contains(sees)': True, 'contains(complex)': False, 'contains(greatest)': False, 'contains(impact)': False, 'contains(beauty)': False, 'contains(front)': False, 'contains(humans)': False, 'contains(indeed)': False, 'contains(flat)': False, 'contains(grace)': False, 'contains(wrote)': False, 'contains(amusing)': False, 'contains(ii)': False, 'contains(mike)': False, 'contains(further)': False, 'contains(cute)': False, 'contains(dull)': False, 'contains(minor)': False, 'contains(recently)': False, 'contains(hate)': False, 'contains(outside)': False, 'contains(plenty)': False, 'contains(wish)': False, 'contains(godzilla)': False, 'contains(college)': False, 'contains(titanic)': False, 'contains(sounds)': False, 'contains(telling)': False, 'contains(sight)': False, 'contains(double)': False, 'contains(cinematic)': False, 'contains(queen)': False, 'contains(hold)': False, 'contains(meanwhile)': False, 'contains(awful)': False, 'contains(clearly)': False, 'contains(theme)': False, 'contains(hear)': False, 'contains(x)': False, 'contains(amount)': False, 'contains(baby)': False, 'contains(approach)': False, 'contains(dreams)': False, 'contains(shown)': False, 'contains(island)': False, 'contains(reasons)': False, 'contains(charm)': False, 'contains(miss)': True, 'contains(longer)': False, 'contains(common)': False, 'contains(sean)': False, 'contains(carry)': False, 'contains(believable)': False, 'contains(realistic)': False, 'contains(chemistry)': True, 'contains(possibly)': False, 'contains(casting)': False, 'contains(carrey)': False, 'contains(french)': False, 'contains(trailer)': False, 'contains(tough)': False, 'contains(produced)': False, 'contains(imagine)': False, 'contains(choice)': False, 'contains(ride)': False, 'contains(somewhere)': False, 'contains(hot)': False, 'contains(race)': False, 'contains(road)': False, 'contains(leader)': False, 'contains(thin)': False, 'contains(jerry)': False, 'contains(slowly)': False, 'contains(delivers)': False, 'contains(detective)': False, 'contains(brown)': False, 'contains(jackson)': False, 'contains(member)': False, 'contains(provide)': False, 'contains(president)': False, 'contains(puts)': False, 'contains(asks)': False, 'contains(critics)': False, 'contains(appearance)': False, 'contains(famous)': False, 'contains(okay)': False, 'contains(intelligence)': False, 'contains(energy)': False, 'contains(sent)': False, 'contains(spielberg)': False, 'contains(development)': False, 'contains(etc)': False, 'contains(language)': False, 'contains(blue)': False, 'contains(proves)': False, 'contains(vampire)': False, 'contains(seemingly)': False, 'contains(basic)': False, 'contains(caught)': False, 'contains(decide)': False, 'contains(opportunity)': False, 'contains(incredibly)': False, 'contains(images)': False, 'contains(band)': False, 'contains(j)': False, 'contains(writers)': False, 'contains(knew)': False, 'contains(interested)': False, 'contains(considering)': False, 'contains(boys)': False, 'contains(thanks)': False, 'contains(remains)': False, 'contains(climax)': True, 'contains(event)': False, 'contains(directing)': False, 'contains(conclusion)': False, 'contains(leading)': False, 'contains(ground)': False, 'contains(lies)': False, 'contains(forget)': False, 'contains(alive)': False, 'contains(tarzan)': False, 'contains(century)': False, 'contains(provides)': False, 'contains(trip)': False, 'contains(partner)': False, 'contains(central)': False, 'contains(tarantino)': False, 'contains(period)': False, 'contains(pace)': False, 'contains(yourself)': False, 'contains(worked)': False, 'contains(ready)': False, 'contains(date)': False, 'contains(thus)': False, 'contains(1998)': False, 'contains(terrific)': False, 'contains(write)': False, 'contains(average)': False, 'contains(onto)': False, 'contains(songs)': False, 'contains(occasionally)': False, 'contains(doctor)': False, 'contains(stands)': False, 'contains(hardly)': False, 'contains(monster)': False, 'contains(led)': False, 'contains(mysterious)': False, 'contains(details)': False, 'contains(wasted)': False, 'contains(apart)': False, 'contains(aside)': False, 'contains(store)': False, 'contains(billy)': False, 'contains(boss)': True, 'contains(travolta)': False, 'contains(producer)': False, 'contains(pull)': False, 'contains(consider)': False, 'contains(pictures)': False, 'contains(becoming)': False, 'contains(cage)': False, 'contains(loud)': False, 'contains(looked)': False, 'contains(officer)': False, 'contains(twenty)': False, 'contains(system)': False, 'contains(contains)': False, 'contains(julia)': False, 'contains(subplot)': False, 'contains(missing)': False, 'contains(personality)': False, 'contains(building)': False, 'contains(learns)': False, 'contains(hong)': True, 'contains(la)': False, 'contains(apartment)': False, 'contains(7)': False, 'contains(bizarre)': False, 'contains(powers)': False, 'contains(flaws)': False, 'contains(catch)': False, 'contains(lawyer)': False, 'contains(shoot)': False, 'contains(student)': False, 'contains(unique)': True, 'contains(000)': False, 'contains(admit)': False, 'contains(concept)': False, 'contains(needed)': False, 'contains(thrown)': False, 'contains(christopher)': False, 'contains(laughing)': False, 'contains(green)': False, 'contains(twists)': False, 'contains(matthew)': False, 'contains(touch)': False, 'contains(waiting)': False, 'contains(victim)': False, 'contains(cover)': False, 'contains(machine)': False, 'contains(danny)': False, 'contains(mention)': False, 'contains(search)': False, 'contains(1997)': False, 'contains(win)': False, 'contains(door)': False, 'contains(manner)': False, 'contains(train)': True, 'contains(saving)': False, 'contains(share)': False, 'contains(image)': False, 'contains(discovers)': False, 'contains(normal)': False, 'contains(cross)': False, 'contains(fox)': False, 'contains(returns)': False, 'contains(adult)': False, 'contains(adds)': False, 'contains(answer)': False, 'contains(adventure)': False, 'contains(lame)': False, 'contains(male)': False, 'contains(odd)': False, 'contains(singer)': False, 'contains(deserves)': False, 'contains(gore)': False, 'contains(states)': False, 'contains(include)': False, 'contains(equally)': False, 'contains(months)': False, 'contains(barely)': False, 'contains(directors)': False, 'contains(introduced)': False, 'contains(fashion)': False, 'contains(social)': False, 'contains(1999)': False, 'contains(news)': False, 'contains(hair)': False, 'contains(dance)': False, 'contains(innocent)': False, 'contains(camp)': False, 'contains(teacher)': False, 'contains(became)': False, 'contains(sad)': False, 'contains(witch)': False, 'contains(includes)': False, 'contains(nights)': False, 'contains(jason)': False, 'contains(julie)': False, 'contains(latter)': False, 'contains(food)': True, 'contains(jennifer)': False, 'contains(land)': False, 'contains(menace)': False, 'contains(rate)': False, 'contains(storyline)': False, 'contains(contact)': False, 'contains(jean)': False, 'contains(elizabeth)': False, 'contains(fellow)': False, 'contains(changes)': False, 'contains(henry)': False, 'contains(hill)': False, 'contains(pulp)': False, 'contains(gay)': False, 'contains(tried)': False, 'contains(surprised)': False, 'contains(literally)': False, 'contains(walk)': False, 'contains(standard)': False, 'contains(90)': False, 'contains(forward)': False, 'contains(wise)': False, 'contains(enjoyed)': False, 'contains(discover)': False, 'contains(pop)': False, 'contains(anderson)': False, 'contains(offer)': False, 'contains(recommend)': False, 'contains(public)': False, 'contains(drive)': False, 'contains(c)': False, 'contains(toy)': False, 'contains(charming)': False, 'contains(fair)': False, 'contains(chinese)': True, 'contains(rescue)': False, 'contains(terms)': False, 'contains(mouth)': False, 'contains(lucas)': False, 'contains(accident)': False, 'contains(dies)': False, 'contains(decided)': False, 'contains(edge)': False, 'contains(footage)': False, 'contains(culture)': False, 'contains(weak)': False, 'contains(presented)': False, 'contains(blade)': False, 'contains(younger)': False, 'contains(douglas)': False, 'contains(natural)': False, 'contains(born)': False, 'contains(generally)': False, 'contains(teenage)': False, 'contains(older)': False, 'contains(horrible)': False, 'contains(addition)': False, 'contains(sadly)': False, 'contains(creates)': False, 'contains(disturbing)': False, 'contains(roger)': False, 'contains(detail)': False, 'contains(devil)': False, 'contains(debut)': False, 'contains(track)': False, 'contains(developed)': False, 'contains(week)': False, 'contains(russell)': False, 'contains(attack)': False, 'contains(explain)': False, 'contains(rarely)': False, 'contains(fully)': False, 'contains(prove)': False, 'contains(exception)': False, 'contains(jeff)': False, 'contains(twist)': False, 'contains(gang)': False, 'contains(winning)': False, 'contains(jr)': False, 'contains(species)': False, 'contains(issues)': False, 'contains(fresh)': False, 'contains(rules)': False, 'contains(meaning)': False, 'contains(inspired)': False, 'contains(heroes)': False, 'contains(desperate)': False, 'contains(fighting)': False, 'contains(filmed)': False, 'contains(faces)': False, 'contains(alan)': False, 'contains(bright)': False, 'contains(ass)': True, 'contains(flying)': False, 'contains(kong)': True, 'contains(rush)': False, 'contains(forces)': False, 'contains(charles)': False, 'contains(numerous)': False, 'contains(emotions)': False, 'contains(involves)': True, 'contains(patrick)': False, 'contains(weird)': False, 'contains(apparent)': False, 'contains(information)': False, 'contains(revenge)': False, 'contains(jay)': False, 'contains(toward)': False, 'contains(surprising)': False, 'contains(twice)': False, 'contains(editing)': False, 'contains(calls)': False, 'contains(lose)': False, 'contains(vegas)': False, 'contains(stage)': False, 'contains(intended)': False, 'contains(gags)': False, 'contains(opinion)': False, 'contains(likes)': False, 'contains(crazy)': False, 'contains(owner)': False, 'contains(places)': False, 'contains(pair)': False, 'contains(genuine)': False, 'contains(epic)': False, 'contains(speak)': False, 'contains(throw)': False, 'contains(appeal)': False, 'contains(gibson)': False, 'contains(captain)': False, 'contains(military)': False, 'contains(20)': False, 'contains(blair)': False, 'contains(nowhere)': False, 'contains(length)': False, 'contains(nicely)': False, 'contains(cause)': False, 'contains(pass)': False, 'contains(episode)': False, 'contains(kiss)': False, 'contains(arnold)': True, 'contains(please)': False, 'contains(hasn)': False, 'contains(phone)': False, 'contains(filmmaking)': False, 'contains(formula)': False, 'contains(boyfriend)': False, 'contains(talents)': False, 'contains(creating)': False, 'contains(kelly)': False, 'contains(buy)': False, 'contains(wide)': False, 'contains(fantasy)': False, 'contains(mood)': False, 'contains(heads)': False, 'contains(pathetic)': False, 'contains(lacks)': False, 'contains(loved)': False, 'contains(asked)': False, 'contains(mrs)': False, 'contains(witty)': False, 'contains(shakespeare)': False, 'contains(mulan)': False, 'contains(generation)': False, 'contains(affair)': False, 'contains(pieces)': False, 'contains(task)': False, 'contains(rare)': False, 'contains(kept)': False, 'contains(cameo)': False, 'contains(fascinating)': False, 'contains(ed)': False, 'contains(fbi)': False, 'contains(burton)': False, 'contains(incredible)': False, 'contains(accent)': False, 'contains(artist)': False, 'contains(superior)': False, 'contains(academy)': False, 'contains(thomas)': False, 'contains(spirit)': False, 'contains(technical)': False, 'contains(confusing)': False, 'contains(poorly)': False, 'contains(target)': False, 'contains(lover)': False, 'contains(woo)': False, 'contains(mentioned)': False, 'contains(theaters)': False, 'contains(plane)': False, 'contains(confused)': False, 'contains(dennis)': False, 'contains(rob)': False, 'contains(appropriate)': False, 'contains(christmas)': False, 'contains(considered)': False, 'contains(legend)': False, 'contains(shame)': False, 'contains(soul)': False, 'contains(matt)': False, 'contains(campbell)': False, 'contains(process)': False, 'contains(bottom)': False, 'contains(sitting)': False, 'contains(brain)': False, 'contains(creepy)': False, 'contains(13)': False, 'contains(forever)': False, 'contains(dude)': False, 'contains(crap)': False, 'contains(superb)': False, 'contains(speech)': False, 'contains(ice)': False, 'contains(journey)': False, 'contains(masterpiece)': False, 'contains(intriguing)': False, 'contains(names)': False, 'contains(pick)': False, 'contains(speaking)': False, 'contains(virtually)': False, 'contains(award)': False, 'contains(worthy)': False, 'contains(marriage)': False, 'contains(deliver)': False, 'contains(cash)': False, 'contains(magic)': False, 'contains(respect)': False, 'contains(product)': False, 'contains(necessary)': False, 'contains(suppose)': False, 'contains(silent)': False, 'contains(pointless)': False, 'contains(station)': False, 'contains(affleck)': False, 'contains(dimensional)': False, 'contains(charlie)': False, 'contains(allows)': False, 'contains(avoid)': False, 'contains(meant)': False, 'contains(cops)': False, 'contains(attitude)': False, 'contains(relationships)': False, 'contains(hits)': False, 'contains(stephen)': False, 'contains(spends)': False, 'contains(relief)': False, 'contains(physical)': True, 'contains(count)': False, 'contains(reviews)': False, 'contains(appreciate)': False, 'contains(cliches)': False, 'contains(holds)': False, 'contains(pure)': False, 'contains(plans)': False, 'contains(limited)': False, 'contains(failed)': False, 'contains(pain)': False, 'contains(impression)': False, 'contains(unless)': False, 'contains(sub)': False, 'contains([)': False, 'contains(total)': False, 'contains(creature)': False, 'contains(viewing)': False, 'contains(loves)': False, 'contains(princess)': False, 'contains(kate)': False, 'contains(rising)': False, 'contains(woods)': False, 'contains(baldwin)': False, 'contains(angry)': False, 'contains(drawn)': False, 'contains(step)': False, 'contains(matrix)': False, 'contains(themes)': False, 'contains(satire)': False, 'contains(arts)': False, 'contains(])': False, 'contains(remake)': False, 'contains(wall)': False, 'contains(moral)': False, 'contains(color)': False, 'contains(ray)': False, 'contains(stuck)': False, 'contains(touching)': False, 'contains(wit)': False, 'contains(tony)': False, 'contains(hanks)': False, 'contains(continues)': False, 'contains(damn)': False, 'contains(nobody)': False, 'contains(cartoon)': False, 'contains(keeping)': False, 'contains(realized)': False, 'contains(criminal)': False, 'contains(unfunny)': False, 'contains(comedic)': False, 'contains(martial)': False, 'contains(disappointing)': False, 'contains(anti)': False, 'contains(graphic)': False, 'contains(stunning)': False, 'contains(actions)': False, 'contains(floor)': False, 'contains(emotion)': False, 'contains(soldiers)': False, 'contains(edward)': False, 'contains(comedies)': False, 'contains(driver)': False, 'contains(expectations)': False, 'contains(added)': False, 'contains(mad)': False, 'contains(angels)': False, 'contains(shallow)': False, 'contains(suspect)': False, 'contains(humorous)': False, 'contains(phantom)': False, 'contains(appealing)': False, 'contains(device)': False, 'contains(design)': False, 'contains(industry)': False, 'contains(reach)': False, 'contains(fat)': False, 'contains(blame)': False, 'contains(united)': False, 'contains(sign)': False, 'contains(portrayal)': False, 'contains(rocky)': False, 'contains(finale)': False, 'contains(grand)': False, 'contains(opposite)': False, 'contains(hotel)': False, 'contains(match)': False, 'contains(damme)': False, 'contains(speed)': False, 'contains(ok)': False, 'contains(loving)': False, 'contains(field)': True, 'contains(larry)': False, 'contains(urban)': False, 'contains(troopers)': False, 'contains(compared)': False, 'contains(apes)': False, 'contains(rose)': False, 'contains(falling)': False, 'contains(era)': False, 'contains(loses)': False, 'contains(adults)': False, 'contains(managed)': False, 'contains(dad)': False, 'contains(therefore)': False, 'contains(pg)': False, 'contains(results)': False, 'contains(guns)': False, 'contains(radio)': False, 'contains(lady)': False, 'contains(manage)': False, 'contains(spice)': False, 'contains(naked)': False, 'contains(started)': False, 'contains(intense)': False, 'contains(humanity)': False, 'contains(wonderfully)': False, 'contains(slasher)': False, 'contains(bland)': False, 'contains(imagination)': False, 'contains(walking)': False, 'contains(willing)': False, 'contains(horse)': False, 'contains(rent)': False, 'contains(mix)': False, 'contains(generated)': False, 'contains(g)': False, 'contains(utterly)': False, 'contains(scientist)': False, 'contains(washington)': False, 'contains(notice)': False, 'contains(players)': False, 'contains(teenagers)': False, 'contains(moore)': False, 'contains(board)': False, 'contains(price)': False, 'contains(frightening)': False, 'contains(tommy)': False, 'contains(spectacular)': False, 'contains(bored)': False, 'contains(jane)': False, 'contains(join)': False, 'contains(producers)': False, 'contains(johnny)': False, 'contains(zero)': False, 'contains(vampires)': False, 'contains(adaptation)': False, 'contains(dollars)': False, 'contains(parody)': False, 'contains(documentary)': False, 'contains(dvd)': False, 'contains(wayne)': False, 'contains(post)': False, 'contains(exist)': False, 'contains(matters)': False, 'contains(chosen)': False, 'contains(mel)': False, 'contains(attractive)': True, 'contains(plain)': False, 'contains(trust)': False, 'contains(safe)': False, 'contains(reading)': False, 'contains(hoping)': False, 'contains(protagonist)': False, 'contains(feelings)': False, 'contains(fate)': False, 'contains(finding)': False, 'contains(feet)': False, 'contains(visuals)': False, 'contains(spawn)': False, 'contains(compelling)': False, 'contains(hall)': False, 'contains(sympathetic)': False, 'contains(featuring)': False, 'contains(difference)': False, 'contains(professional)': False, 'contains(drugs)': False, 'contains(ford)': False, 'contains(shooting)': False, 'contains(gold)': False, 'contains(patch)': False, 'contains(build)': False, 'contains(boat)': False, 'contains(cruise)': False, 'contains(honest)': False, 'contains(media)': False, 'contains(flicks)': False, 'contains(bug)': False, 'contains(bringing)': False, 'contains(dangerous)': True, 'contains(watched)': False, 'contains(grant)': False, 'contains(smile)': False, 'contains(plus)': False, 'contains(shouldn)': False, 'contains(decision)': False, 'contains(visually)': False, 'contains(allow)': False, 'contains(starship)': False, 'contains(roberts)': False, 'contains(dying)': False, 'contains(portrayed)': False, 'contains(turning)': False, 'contains(believes)': False, 'contains(changed)': False, 'contains(shock)': False, 'contains(destroy)': False, 'contains(30)': False, 'contains(crowd)': False, 'contains(broken)': False, 'contains(tired)': False, 'contains(fail)': False, 'contains(south)': False, 'contains(died)': False, 'contains(cult)': False, 'contains(fake)': False, 'contains(vincent)': False, 'contains(identity)': False, 'contains(sexy)': False, 'contains(hunt)': False, 'contains(jedi)': False, 'contains(flynt)': False, 'contains(alex)': False, 'contains(engaging)': False, 'contains(serve)': False, 'contains(snake)': False, 'contains(yeah)': False, 'contains(expecting)': False, 'contains(100)': False, 'contains(decade)': False, 'contains(ups)': False, 'contains(constant)': False, 'contains(current)': False, 'contains(survive)': False, 'contains(jimmy)': False, 'contains(buddy)': False, 'contains(send)': False, 'contains(brooks)': False, 'contains(goofy)': False, 'contains(likable)': False, 'contains(humour)': False, 'contains(technology)': False, 'contains(files)': False, 'contains(babe)': False, 'contains(aspects)': False, 'contains(presents)': False, 'contains(kills)': False, 'contains(supposedly)': False, 'contains(eight)': True, 'contains(sandler)': False, 'contains(hospital)': False, 'contains(test)': False, 'contains(hidden)': False, 'contains(brian)': False, 'contains(books)': False, 'contains(promise)': False, 'contains(determined)': False, 'contains(professor)': False, 'contains(welcome)': False, 'contains(pleasure)': False, 'contains(succeeds)': False, 'contains(individual)': False, 'contains(annie)': False, 'contains(mob)': False, 'contains(ted)': False, 'contains(virus)': False, 'contains(content)': False, 'contains(gary)': False, 'contains(direct)': False, 'contains(contrived)': False, 'contains(carpenter)': False, 'contains(scale)': False, 'contains(sick)': False, 'contains(nasty)': False, 'contains(conflict)': False, 'contains(haunting)': False, 'contains(ghost)': False, 'contains(filmmaker)': False, 'contains(japanese)': False, 'contains(helps)': False, 'contains(fare)': False, 'contains(lucky)': False, 'contains(ultimate)': False, 'contains(window)': False, 'contains(support)': False, 'contains(goal)': False, 'contains(provided)': False, 'contains(genius)': False, 'contains(winner)': False, 'contains(taylor)': False, 'contains(fantastic)': False, 'contains(faith)': False, 'contains(lynch)': False, 'contains(fit)': False, 'contains(catherine)': False, 'contains(ms)': False, 'contains(paced)': False, 'contains(breaks)': False, 'contains(al)': False, 'contains(frame)': False, 'contains(travel)': False, 'contains(badly)': False, 'contains(available)': False, 'contains(cares)': False, 'contains(reeves)': False, 'contains(crash)': False, 'contains(driving)': False, 'contains(press)': False, 'contains(seagal)': False, 'contains(amy)': False, 'contains(9)': False, 'contains(headed)': False, 'contains(instance)': False, 'contains(excuse)': False, 'contains(offensive)': False, 'contains(narrative)': False, 'contains(fault)': False, 'contains(bus)': False, 'contains(f)': False, 'contains(extreme)': False, 'contains(miller)': False, 'contains(guilty)': False, 'contains(grows)': False, 'contains(overly)': False, 'contains(liners)': False, 'contains(forgotten)': False, 'contains(ahead)': False, 'contains(accept)': False, 'contains(porn)': False, 'contains(directly)': False, 'contains(helen)': False, 'contains(began)': False, 'contains(lord)': False, 'contains(folks)': False, 'contains(mediocre)': False, 'contains(bar)': False, 'contains(surface)': False, 'contains(super)': False, 'contains(failure)': False, 'contains(6)': False, 'contains(acted)': False, 'contains(quiet)': False, 'contains(laughable)': False, 'contains(sheer)': False, 'contains(security)': True, 'contains(emotionally)': False, 'contains(season)': False, 'contains(stuart)': False, 'contains(jail)': True, 'contains(deals)': False, 'contains(cheesy)': False, 'contains(court)': False, 'contains(beach)': False, 'contains(austin)': False, 'contains(model)': False, 'contains(outstanding)': False, 'contains(substance)': False, 'contains(nudity)': False, 'contains(slapstick)': False, 'contains(joan)': False, 'contains(reveal)': False, 'contains(placed)': False, 'contains(check)': False, 'contains(beast)': False, 'contains(hurt)': False, 'contains(bloody)': False, 'contains(acts)': False, 'contains(fame)': False, 'contains(meeting)': False, 'contains(nuclear)': False, 'contains(1996)': False, 'contains(strength)': False, 'contains(center)': False, 'contains(funniest)': False, 'contains(standing)': True, 'contains(damon)': False, 'contains(clich)': False, 'contains(position)': False, 'contains(desire)': False, 'contains(driven)': False, 'contains(seat)': False, 'contains(stock)': False, 'contains(wondering)': True, 'contains(realizes)': False, 'contains(dealing)': False, 'contains(taste)': False, 'contains(routine)': False, 'contains(comparison)': False, 'contains(cinematographer)': False, 'contains(seconds)': False, 'contains(singing)': False, 'contains(gangster)': True, 'contains(responsible)': False, 'contains(football)': False, 'contains(remarkable)': False, 'contains(hunting)': False, 'contains(adams)': False, 'contains(fly)': False, 'contains(suspects)': False, 'contains(treat)': False, 'contains(hopes)': False, 'contains(heaven)': False, 'contains(myers)': False, 'contains(struggle)': False, 'contains(costumes)': False, 'contains(beat)': False, 'contains(happening)': False, 'contains(skills)': False, 'contains(ugly)': False, 'contains(figures)': False, 'contains(thoroughly)': False, 'contains(ill)': False, 'contains(surprises)': False, 'contains(player)': False, 'contains(rival)': False, 'contains(guard)': True, 'contains(anthony)': False, 'contains(strike)': False, 'contains(community)': False, 'contains(streets)': False, 'contains(hopkins)': False, 'contains(ended)': False, 'contains(originally)': False, 'contains(sarah)': False, 'contains(creative)': False, 'contains(characterization)': False, 'contains(thankfully)': False, 'contains(growing)': False, 'contains(sharp)': False, 'contains(williamson)': False, 'contains(eccentric)': False, 'contains(explained)': False, 'contains(hey)': False, 'contains(claire)': False, 'contains(steal)': False, 'contains(inevitable)': False, 'contains(joel)': False, 'contains(core)': False, 'contains(weren)': False, 'contains(sorry)': False, 'contains(built)': False, 'contains(anne)': False, 'contains(breaking)': False, 'contains(villains)': False, 'contains(critic)': False, 'contains(lets)': False, 'contains(visit)': False, 'contains(followed)': False}\n"
          ]
        }
      ],
      "source": [
        "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())\n",
        "word_features = list(all_words)[:2000]\n",
        "\n",
        "def document_features(document):\n",
        "    document_words = set(document)\n",
        "    features = {}\n",
        "    for word in word_features:\n",
        "        features['contains({})'.format(word)] = (word in document_words)\n",
        "    return features\n",
        "print(document_features(movie_reviews.words('pos/cv957_8737.txt')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ec34096a",
      "metadata": {
        "id": "ec34096a",
        "outputId": "dc9d9140-0c3d-4ad1-fbd4-049530cd59aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.72\n"
          ]
        }
      ],
      "source": [
        "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
        "train_set, test_set = featuresets[100:], featuresets[:100]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, test_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5a624e93",
      "metadata": {
        "id": "5a624e93",
        "outputId": "aee9d632-1ad0-4b23-8cb4-53f11b42d69a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "        contains(seagal) = True              neg : pos    =     11.6 : 1.0\n",
            "   contains(outstanding) = True              pos : neg    =     11.2 : 1.0\n",
            "         contains(mulan) = True              pos : neg    =      8.4 : 1.0\n",
            "   contains(wonderfully) = True              pos : neg    =      6.8 : 1.0\n",
            "        contains(wasted) = True              neg : pos    =      6.4 : 1.0\n"
          ]
        }
      ],
      "source": [
        "classifier.show_most_informative_features(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "08a3009e",
      "metadata": {
        "id": "08a3009e",
        "outputId": "0ccbec79-cd26-4608-9bb3-addaaae8193b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['e', ',', '.', 's', 'd', 't', 'he', 'n', 'a', 'of', 'the', 'y', 'r', 'to', 'in', 'f', 'o', 'ed', 'nd', 'is', 'on', 'l', 'g', 'and', 'ng', 'er', 'as', 'ing', 'h', 'at', 'es', 'or', 're', 'it', '``', 'an', \"''\", 'm', ';', 'i', 'ly', 'ion', 'en', 'al', '?', 'nt', 'be', 'hat', 'st', 'his', 'th', 'll', 'le', 'ce', 'by', 'ts', 'me', 've', \"'\", 'se', 'ut', 'was', 'for', 'ent', 'ch', 'k', 'w', 'ld', '`', 'rs', 'ted', 'ere', 'her', 'ne', 'ns', 'ith', 'ad', 'ry', ')', '(', 'te', '--', 'ay', 'ty', 'ot', 'p', 'nce', \"'s\", 'ter', 'om', 'ss', ':', 'we', 'are', 'c', 'ers', 'uld', 'had', 'so', 'ey']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import brown\n",
        "suffix_fdist = nltk.FreqDist()\n",
        "for word in brown.words():\n",
        "    word = word.lower()\n",
        "    suffix_fdist[word[-1:]] += 1\n",
        "    suffix_fdist[word[-2:]] += 1\n",
        "    suffix_fdist[word[-3:]] += 1\n",
        "common_suffixes = [suffix for (suffix, count) in suffix_fdist.most_common(100)]\n",
        "print(common_suffixes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "f04f737f",
      "metadata": {
        "id": "f04f737f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3914"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.corpus import treebank\n",
        "len(treebank.tagged_sents())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "d9ba73e3",
      "metadata": {
        "id": "d9ba73e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('At', 'IN'),\n",
              " ('Tokyo', 'NNP'),\n",
              " (',', ','),\n",
              " ('the', 'DT'),\n",
              " ('Nikkei', 'NNP'),\n",
              " ('index', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('225', 'CD'),\n",
              " ('selected', 'VBN'),\n",
              " ('issues', 'NNS'),\n",
              " (',', ','),\n",
              " ('which', 'WDT'),\n",
              " ('*T*-1', '-NONE-'),\n",
              " ('gained', 'VBD'),\n",
              " ('132', 'CD'),\n",
              " ('points', 'NNS'),\n",
              " ('Tuesday', 'NNP'),\n",
              " (',', ','),\n",
              " ('added', 'VBD'),\n",
              " ('14.99', 'CD'),\n",
              " ('points', 'NNS'),\n",
              " ('to', 'TO'),\n",
              " ('35564.43', 'CD'),\n",
              " ('.', '.')]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data = treebank.tagged_sents()[:3000]\n",
        "test_data = treebank.tagged_sents()[3000:]\n",
        "train_data[0]\n",
        "test_data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "d05aa365",
      "metadata": {
        "id": "d05aa365"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.875545003237643"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tag import tnt\n",
        "tnt_pos_tagger = tnt.TnT()\n",
        "tnt_pos_tagger.train(train_data)\n",
        "tnt_pos_tagger.accuracy(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "b295191b",
      "metadata": {
        "id": "b295191b"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "write() argument must be str, not bytes",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[56], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m      2\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnt_treebank_pos_tagger.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtnt_pos_tagger\u001b[49m\u001b[43m,\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m f\u001b[38;5;241m.\u001b[39mclose()\n",
            "\u001b[1;31mTypeError\u001b[0m: write() argument must be str, not bytes"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "f = open('tnt_treebank_pos_tagger.pickle','w')\n",
        "pickle.dump(tnt_pos_tagger,f)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "f74d6079",
      "metadata": {
        "id": "f74d6079"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('this', 'DT'),\n",
              " ('is', 'VBZ'),\n",
              " ('tnt', 'Unk'),\n",
              " ('treebank', 'Unk'),\n",
              " ('tagger', 'Unk')]"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tnt_pos_tagger.tag(nltk.word_tokenize(\"this is tnt treebank tagger\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "eef3c49e",
      "metadata": {
        "id": "eef3c49e",
        "outputId": "d7adce04-1d24-4c7c-bc90-c2d9c882c59b"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[66], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(featuresets) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m      9\u001b[0m train_set, test_set \u001b[38;5;241m=\u001b[39m featuresets[size:], featuresets[:size]\n\u001b[1;32m---> 10\u001b[0m classifier \u001b[38;5;241m=\u001b[39m \u001b[43mnltk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDecisionTreeClassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m nltk\u001b[38;5;241m.\u001b[39mclassify\u001b[38;5;241m.\u001b[39maccuracy(classifier, test_set)\n",
            "File \u001b[1;32mc:\\Users\\maswa\\UserFiles\\aswarth\\aswarth\\RVCE\\Sem5\\nlp\\venv\\Lib\\site-packages\\nltk\\classify\\decisiontree.py:175\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.train\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    170\u001b[0m     tree \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier\u001b[38;5;241m.\u001b[39mbest_binary_stump(\n\u001b[0;32m    171\u001b[0m         feature_names, labeled_featuresets, feature_values, verbose\n\u001b[0;32m    172\u001b[0m     )\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# Refine the stump.\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefine\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabeled_featuresets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentropy_cutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdepth_cutoff\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43msupport_cutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# Return it\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
            "File \u001b[1;32mc:\\Users\\maswa\\UserFiles\\aswarth\\aswarth\\RVCE\\Sem5\\nlp\\venv\\Lib\\site-packages\\nltk\\classify\\decisiontree.py:231\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.refine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    229\u001b[0m     label_freqs \u001b[38;5;241m=\u001b[39m FreqDist(label \u001b[38;5;28;01mfor\u001b[39;00m (featureset, label) \u001b[38;5;129;01min\u001b[39;00m fval_featuresets)\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m entropy(MLEProbDist(label_freqs)) \u001b[38;5;241m>\u001b[39m entropy_cutoff:\n\u001b[1;32m--> 231\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decisions[fval] \u001b[38;5;241m=\u001b[39m \u001b[43mDecisionTreeClassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfval_featuresets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m            \u001b[49m\u001b[43mentropy_cutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdepth_cutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43msupport_cutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeature_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     default_featuresets \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    242\u001b[0m         (featureset, label)\n\u001b[0;32m    243\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (featureset, label) \u001b[38;5;129;01min\u001b[39;00m labeled_featuresets\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m featureset\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fname) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decisions\n\u001b[0;32m    245\u001b[0m     ]\n",
            "File \u001b[1;32mc:\\Users\\maswa\\UserFiles\\aswarth\\aswarth\\RVCE\\Sem5\\nlp\\venv\\Lib\\site-packages\\nltk\\classify\\decisiontree.py:175\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.train\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    170\u001b[0m     tree \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier\u001b[38;5;241m.\u001b[39mbest_binary_stump(\n\u001b[0;32m    171\u001b[0m         feature_names, labeled_featuresets, feature_values, verbose\n\u001b[0;32m    172\u001b[0m     )\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# Refine the stump.\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefine\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabeled_featuresets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentropy_cutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdepth_cutoff\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43msupport_cutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# Return it\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
            "File \u001b[1;32mc:\\Users\\maswa\\UserFiles\\aswarth\\aswarth\\RVCE\\Sem5\\nlp\\venv\\Lib\\site-packages\\nltk\\classify\\decisiontree.py:231\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.refine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    229\u001b[0m     label_freqs \u001b[38;5;241m=\u001b[39m FreqDist(label \u001b[38;5;28;01mfor\u001b[39;00m (featureset, label) \u001b[38;5;129;01min\u001b[39;00m fval_featuresets)\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m entropy(MLEProbDist(label_freqs)) \u001b[38;5;241m>\u001b[39m entropy_cutoff:\n\u001b[1;32m--> 231\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decisions[fval] \u001b[38;5;241m=\u001b[39m \u001b[43mDecisionTreeClassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfval_featuresets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m            \u001b[49m\u001b[43mentropy_cutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdepth_cutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43msupport_cutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeature_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     default_featuresets \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    242\u001b[0m         (featureset, label)\n\u001b[0;32m    243\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (featureset, label) \u001b[38;5;129;01min\u001b[39;00m labeled_featuresets\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m featureset\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fname) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decisions\n\u001b[0;32m    245\u001b[0m     ]\n",
            "    \u001b[1;31m[... skipping similar frames: DecisionTreeClassifier.refine at line 231 (13 times), DecisionTreeClassifier.train at line 175 (13 times)]\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\maswa\\UserFiles\\aswarth\\aswarth\\RVCE\\Sem5\\nlp\\venv\\Lib\\site-packages\\nltk\\classify\\decisiontree.py:175\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.train\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    170\u001b[0m     tree \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier\u001b[38;5;241m.\u001b[39mbest_binary_stump(\n\u001b[0;32m    171\u001b[0m         feature_names, labeled_featuresets, feature_values, verbose\n\u001b[0;32m    172\u001b[0m     )\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# Refine the stump.\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrefine\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabeled_featuresets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentropy_cutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdepth_cutoff\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43msupport_cutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# Return it\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tree\n",
            "File \u001b[1;32mc:\\Users\\maswa\\UserFiles\\aswarth\\aswarth\\RVCE\\Sem5\\nlp\\venv\\Lib\\site-packages\\nltk\\classify\\decisiontree.py:231\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.refine\u001b[1;34m(self, labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    229\u001b[0m     label_freqs \u001b[38;5;241m=\u001b[39m FreqDist(label \u001b[38;5;28;01mfor\u001b[39;00m (featureset, label) \u001b[38;5;129;01min\u001b[39;00m fval_featuresets)\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m entropy(MLEProbDist(label_freqs)) \u001b[38;5;241m>\u001b[39m entropy_cutoff:\n\u001b[1;32m--> 231\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decisions[fval] \u001b[38;5;241m=\u001b[39m \u001b[43mDecisionTreeClassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfval_featuresets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m            \u001b[49m\u001b[43mentropy_cutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdepth_cutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43msupport_cutoff\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbinary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeature_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     default_featuresets \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    242\u001b[0m         (featureset, label)\n\u001b[0;32m    243\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (featureset, label) \u001b[38;5;129;01min\u001b[39;00m labeled_featuresets\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m featureset\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fname) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decisions\n\u001b[0;32m    245\u001b[0m     ]\n",
            "File \u001b[1;32mc:\\Users\\maswa\\UserFiles\\aswarth\\aswarth\\RVCE\\Sem5\\nlp\\venv\\Lib\\site-packages\\nltk\\classify\\decisiontree.py:166\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.train\u001b[1;34m(labeled_featuresets, entropy_cutoff, depth_cutoff, support_cutoff, binary, feature_values, verbose)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# Start with a stump.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m binary:\n\u001b[1;32m--> 166\u001b[0m     tree \u001b[38;5;241m=\u001b[39m \u001b[43mDecisionTreeClassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_stump\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabeled_featuresets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     tree \u001b[38;5;241m=\u001b[39m DecisionTreeClassifier\u001b[38;5;241m.\u001b[39mbest_binary_stump(\n\u001b[0;32m    171\u001b[0m         feature_names, labeled_featuresets, feature_values, verbose\n\u001b[0;32m    172\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\maswa\\UserFiles\\aswarth\\aswarth\\RVCE\\Sem5\\nlp\\venv\\Lib\\site-packages\\nltk\\classify\\decisiontree.py:263\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.best_stump\u001b[1;34m(feature_names, labeled_featuresets, verbose)\u001b[0m\n\u001b[0;32m    261\u001b[0m best_error \u001b[38;5;241m=\u001b[39m best_stump\u001b[38;5;241m.\u001b[39merror(labeled_featuresets)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m feature_names:\n\u001b[1;32m--> 263\u001b[0m     stump \u001b[38;5;241m=\u001b[39m \u001b[43mDecisionTreeClassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabeled_featuresets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    264\u001b[0m     stump_error \u001b[38;5;241m=\u001b[39m stump\u001b[38;5;241m.\u001b[39merror(labeled_featuresets)\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stump_error \u001b[38;5;241m<\u001b[39m best_error:\n",
            "File \u001b[1;32mc:\\Users\\maswa\\UserFiles\\aswarth\\aswarth\\RVCE\\Sem5\\nlp\\venv\\Lib\\site-packages\\nltk\\classify\\decisiontree.py:195\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.stump\u001b[1;34m(feature_name, labeled_featuresets)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstump\u001b[39m(feature_name, labeled_featuresets):\n\u001b[1;32m--> 195\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[43mFreqDist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatureset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabeled_featuresets\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmax()\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;66;03m# Find the best label for each value.\u001b[39;00m\n\u001b[0;32m    198\u001b[0m     freqs \u001b[38;5;241m=\u001b[39m defaultdict(FreqDist)  \u001b[38;5;66;03m# freq(label|value)\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\maswa\\UserFiles\\aswarth\\aswarth\\RVCE\\Sem5\\nlp\\venv\\Lib\\site-packages\\nltk\\probability.py:102\u001b[0m, in \u001b[0;36mFreqDist.__init__\u001b[1;34m(self, samples)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     87\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;124;03m    Construct a new frequency distribution.  If ``samples`` is\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;124;03m    given, then the frequency distribution will be initialized\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m    :type samples: Sequence\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m     \u001b[43mCounter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;66;03m# Cached number of samples in this FreqDist\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mC:\\Python311\\Lib\\collections\\__init__.py:597\u001b[0m, in \u001b[0;36mCounter.__init__\u001b[1;34m(self, iterable, **kwds)\u001b[0m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Create a new, empty Counter object.  And if given, count elements\u001b[39;00m\n\u001b[0;32m    587\u001b[0m \u001b[38;5;124;03mfrom an input iterable.  Or, initialize the count from another mapping\u001b[39;00m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;124;03mof elements to their counts.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    594\u001b[0m \n\u001b[0;32m    595\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m--> 597\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\maswa\\UserFiles\\aswarth\\aswarth\\RVCE\\Sem5\\nlp\\venv\\Lib\\site-packages\\nltk\\probability.py:140\u001b[0m, in \u001b[0;36mFreqDist.update\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;124;03mOverride ``Counter.update()`` to invalidate the cached N\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 140\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mC:\\Python311\\Lib\\collections\\__init__.py:688\u001b[0m, in \u001b[0;36mCounter.update\u001b[1;34m(self, iterable, **kwds)\u001b[0m\n\u001b[0;32m    686\u001b[0m             \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mupdate(iterable)\n\u001b[0;32m    687\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 688\u001b[0m         _count_elements(\u001b[38;5;28mself\u001b[39m, iterable)\n\u001b[0;32m    689\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds:\n\u001b[0;32m    690\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate(kwds)\n",
            "File \u001b[1;32mc:\\Users\\maswa\\UserFiles\\aswarth\\aswarth\\RVCE\\Sem5\\nlp\\venv\\Lib\\site-packages\\nltk\\probability.py:126\u001b[0m, in \u001b[0;36mFreqDist.__setitem__\u001b[1;34m(self, key, val)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;124;03mOverride ``Counter.__setitem__()`` to invalidate the cached N\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setitem__\u001b[39m(key, val)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def pos_features(word):\n",
        "    features = {}\n",
        "    for suffix in common_suffixes:\n",
        "        features['endswith({})'.format(suffix)] = word.lower().endswith(suffix)\n",
        "    return features\n",
        "tagged_words = brown.tagged_words(categories='news')\n",
        "featuresets = [(pos_features(n), g) for (n,g) in tagged_words]\n",
        "size = int(len(featuresets) * 0.1)\n",
        "train_set, test_set = featuresets[size:], featuresets[:size]\n",
        "classifier = nltk.DecisionTreeClassifier.train(train_set)\n",
        "nltk.classify.accuracy(classifier, test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "af7c8da3",
      "metadata": {
        "id": "af7c8da3",
        "outputId": "45770fd2-4b43-45bd-82d8-78dd585a0dc1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'female'"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier.classify(pos_features('cats'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "2e57cdc0",
      "metadata": {
        "id": "2e57cdc0",
        "outputId": "f3de0afa-e35e-4597-c60d-4b7338fe71db"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NaiveBayesClassifier' object has no attribute 'pseudocode'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpseudocode\u001b[49m(depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m))\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'NaiveBayesClassifier' object has no attribute 'pseudocode'"
          ]
        }
      ],
      "source": [
        "print(classifier.pseudocode(depth=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13834b1e",
      "metadata": {
        "id": "13834b1e"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "def pos_features(sentence, i):\n",
        "    features = {\"suffix(1)\": sentence[i][-1:],\n",
        "                \"suffix(2)\": sentence[i][-2:],\n",
        "                \"suffix(3)\": sentence[i][-3:]}\n",
        "    if i == 0:\n",
        "       features[\"prev-word\"] = \"<START>\"\n",
        "    else:\n",
        "        features[\"prev-word\"] = sentence[i-1]\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "143dea66",
      "metadata": {
        "id": "143dea66",
        "outputId": "cd980da7-3290-4ebd-9357-16111271897a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'suffix(1)': 'n', 'suffix(2)': 'on', 'suffix(3)': 'ion', 'prev-word': 'an'}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.corpus import brown\n",
        "pos_features(brown.sents()[0], 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09f99aad",
      "metadata": {
        "id": "09f99aad"
      },
      "outputs": [],
      "source": [
        "sents = nltk.corpus.treebank_raw.sents()\n",
        "tokens = []\n",
        "boundaries = set()\n",
        "offset = 0\n",
        "for sent in sents:\n",
        "    tokens.extend(sent)\n",
        "    offset += len(sent)\n",
        "    boundaries.add(offset-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ac972c3",
      "metadata": {
        "id": "3ac972c3"
      },
      "outputs": [],
      "source": [
        "def punct_features(tokens, i):\n",
        "    return {'next-word-capitalized': tokens[i+1][0].isupper(),\n",
        "            'prev-word': tokens[i-1].lower(),\n",
        "            'punct': tokens[i],\n",
        "            'prev-word-is-one-char': len(tokens[i-1]) == 1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2476e819",
      "metadata": {
        "id": "2476e819"
      },
      "outputs": [],
      "source": [
        "featuresets = [(punct_features(tokens, i), (i in boundaries))\n",
        "                for i in range(1, len(tokens)-1)\n",
        "                if tokens[i] in '.?!']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0f36e41",
      "metadata": {
        "id": "a0f36e41",
        "outputId": "1b310108-ff24-4086-d701-0eb4749c7b71"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.936026936026936"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "size = int(len(featuresets) * 0.1)\n",
        "train_set, test_set = featuresets[size:], featuresets[:size]\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "nltk.classify.accuracy(classifier, test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "003e255f",
      "metadata": {
        "id": "003e255f"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a4178f2",
      "metadata": {
        "id": "7a4178f2"
      },
      "outputs": [],
      "source": [
        "text1 = '''\n",
        "This is a sentence.\n",
        "We are happy!\n",
        "This is another sentence\n",
        "Are you happy?\n",
        "This is Mr. John.\n",
        "He lives in U.K.\n",
        "He earned $8.34.\n",
        "We're happy again.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a369326d",
      "metadata": {
        "id": "a369326d",
        "outputId": "0e989200-f777-480b-df48-075a6e015cc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "This is a sentence.\n",
            "We are happy!\n",
            "This is another sentence\n",
            "Are you happy?\n",
            "This is Mr. John.\n",
            "He lives in U.K.\n",
            "He earned $8.34.\n",
            "We're happy again.\n"
          ]
        }
      ],
      "source": [
        "for sentence in sent_tokenize(text1):\n",
        "    print(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "015c210b",
      "metadata": {
        "id": "015c210b"
      },
      "outputs": [],
      "source": [
        "#Test set - train and test set are simlar here from news\n",
        "import random\n",
        "from nltk.corpus import brown\n",
        "tagged_sents = list(brown.tagged_sents(categories='news'))\n",
        "random.shuffle(tagged_sents)\n",
        "size = int(len(tagged_sents) * 0.1)\n",
        "train_set, test_set = tagged_sents[size:], tagged_sents[:size]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12eba661",
      "metadata": {
        "id": "12eba661"
      },
      "outputs": [],
      "source": [
        "#Better than above as train and test are taken from different documents\n",
        "file_ids = brown.fileids(categories='news')\n",
        "size = int(len(file_ids) * 0.1)\n",
        "train_set = brown.tagged_sents(file_ids[size:])\n",
        "test_set = brown.tagged_sents(file_ids[:size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1cbdd886",
      "metadata": {
        "id": "1cbdd886"
      },
      "outputs": [],
      "source": [
        "#If we want to perform a more stringent evaluation, we can draw the test set from documents that are less closely related to those in the training set\n",
        "train_set = brown.tagged_sents(categories='news')\n",
        "test_set = brown.tagged_sents(categories='fiction')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02947058",
      "metadata": {
        "id": "02947058",
        "outputId": "3b27f61d-476f-4385-cf13-37a25cc6f6da"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#accuracy, measures the percentage of inputs in the test set that the classifier correctly labeled.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m classifier \u001b[38;5;241m=\u001b[39m nltk\u001b[38;5;241m.\u001b[39mNaiveBayesClassifier\u001b[38;5;241m.\u001b[39mtrain(train_set)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(nltk\u001b[38;5;241m.\u001b[39mclassify\u001b[38;5;241m.\u001b[39maccuracy(classifier, test_set))\n",
            "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\nltk\\classify\\naivebayes.py:210\u001b[0m, in \u001b[0;36mNaiveBayesClassifier.train\u001b[1;34m(cls, labeled_featuresets, estimator)\u001b[0m\n\u001b[0;32m    206\u001b[0m fnames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m    208\u001b[0m \u001b[38;5;66;03m# Count up how many times each feature value occurred, given\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;66;03m# the label and featurename.\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m featureset, label \u001b[38;5;129;01min\u001b[39;00m labeled_featuresets:\n\u001b[0;32m    211\u001b[0m     label_freqdist[label] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fname, fval \u001b[38;5;129;01min\u001b[39;00m featureset\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    213\u001b[0m         \u001b[38;5;66;03m# Increment freq(fval|label, fname)\u001b[39;00m\n",
            "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ],
      "source": [
        "#accuracy, measures the percentage of inputs in the test set that the classifier correctly labeled.\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "print(nltk.classify.accuracy(classifier, test_set))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fcb4bc3",
      "metadata": {
        "id": "2fcb4bc3",
        "outputId": "3d3d14fd-5f93-4cea-aeb9-dbe9fc92532c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "                    this = True              neg : pos    =      2.3 : 1.0\n",
            "                    this = False             pos : neg    =      1.8 : 1.0\n",
            "                      an = False             neg : pos    =      1.6 : 1.0\n",
            "                       . = False             neg : pos    =      1.4 : 1.0\n",
            "                       . = True              pos : neg    =      1.4 : 1.0\n",
            "                   about = False             neg : pos    =      1.2 : 1.0\n",
            "                      am = False             pos : neg    =      1.2 : 1.0\n",
            "                 amazing = False             neg : pos    =      1.2 : 1.0\n",
            "                 awesome = False             neg : pos    =      1.2 : 1.0\n",
            "                   beers = False             neg : pos    =      1.2 : 1.0\n",
            "accuracy % 83.33333333333334\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "# Trainng data\n",
        "train = [('I love this sandwich.', 'pos'),\n",
        "         ('This is an amazing place!', 'pos'),\n",
        "         ('I feel very good about these beers.', 'pos'),\n",
        "         ('This is my best work.', 'pos'),\n",
        "         (\"What an awesome view\", 'pos'),\n",
        "         ('I do not like this restaurant', 'neg'),\n",
        "         ('I am tired of this stuff.', 'neg'),\n",
        "         (\"I can't deal with this\", 'neg'),\n",
        "         ('He is my sworn enemy!', 'neg'),\n",
        "         ('My boss is horrible.', 'neg') ]\n",
        "\n",
        "# Test data\n",
        "test = [('The beer was good.', 'pos'),\n",
        "        ('I do not enjoy my job', 'neg'),\n",
        "        (\"I ain't feeling dandy today.\", 'neg'),\n",
        "        (\"I feel amazing!\", 'pos'),\n",
        "        ('Gary is a friend of mine.', 'pos'),\n",
        "        (\"I can't believe I'm doing this.\", 'neg') ]\n",
        "\n",
        "\n",
        "# Tokenize Training words\n",
        "Training_words = set(word.lower() for passage in train for word in word_tokenize(passage[0]))\n",
        "\n",
        "# Training feature sets\n",
        "training_set = [({word: (word in word_tokenize(x[0])) for word in Training_words}, x[1]) for x in train]\n",
        "\n",
        "# Tokenize Test words\n",
        "Test_words = set(word.lower() for passage in test for word in word_tokenize(passage[0]))\n",
        "\n",
        "# Test feature sets\n",
        "test_set= [({word: (word in word_tokenize(x[0])) for word in Test_words}, x[1]) for x in test]\n",
        "\n",
        "# Naive Bayes classifier\n",
        "classifier = nltk.NaiveBayesClassifier.train(training_set)\n",
        "\n",
        "# Informative Features\n",
        "classifier.show_most_informative_features()\n",
        "\n",
        "# print the accuracy\n",
        "print(\"accuracy %\",(nltk.classify.accuracy(classifier, test_set))*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16a489e5",
      "metadata": {
        "id": "16a489e5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
